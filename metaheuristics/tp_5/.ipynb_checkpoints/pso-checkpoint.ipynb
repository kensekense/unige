{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ning\n",
    "#17 Nov\n",
    "#Metaheuristics TP5\n",
    "\n",
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary look at the X.dat file and Y.dat file\n",
    "#Note that 0 corresponds to 'two' and 1 corresponds to 'three'\n",
    "\n",
    "def transfer_file_to_arrays (filename):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            line = line.split(\",\") #split values on ,\n",
    "            for i in range(0, len(line)):\n",
    "                line[i] = float(line[i]) #turn into a float\n",
    "            line = np.array(line)\n",
    "            images.append(line) #append in np array format\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_labels (filename):\n",
    "    labels = []\n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            labels.append(float(line))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "images = transfer_file_to_arrays(\"X.dat\")\n",
    "print(len(images)) #confirm that we have 200 images stored\n",
    "print(images[0].shape[0]) #confirm the shape of the image\n",
    "labels = get_labels(\"Y.dat\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0b39cd2a20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a sample of the image to see if we have one\n",
    "plt.imshow(np.reshape(images[2], (20,20), order=\"F\"), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_two_to_one (theta1, theta2):\n",
    "    return np.concatenate((theta1.flatten(), theta2.flatten()), axis=None)\n",
    "\n",
    "def turn_one_to_two (big_theta):\n",
    "    \n",
    "    theta1 = np.reshape(big_theta[0:10025], (25,401)) #need to be careful here because of shape\n",
    "    theta2 = np.reshape(big_theta[10025:], (1,26))\n",
    "    \n",
    "    return theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a = np.zeros((25,401))\n",
    "b = np.full((1,26),1)\n",
    "\n",
    "ab = turn_two_to_one(a,b)\n",
    "c,d = turn_one_to_two(ab)\n",
    "\n",
    "print(a==c)\n",
    "print(b==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def first_layer (picture):\n",
    "    '''\n",
    "    first layer's role is to download the 400 pixels of the picture\n",
    "    and have one neuron that is the bias \n",
    "    '''\n",
    "    #add bias neuron\n",
    "    layer_n = picture.shape[0]\n",
    "    first_layer = np.insert(picture, layer_n, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return first_layer\n",
    "\n",
    "def second_layer (layer, theta):\n",
    "    '''\n",
    "    second layer contains 25 neurons, plus 1 for the bias\n",
    "    job is to matmul the first layer's output with theta, apply sigmoid function, add bias\n",
    "    \n",
    "    theta is the matrix of size (25, 401)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (25,401)(401,) -> (25,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    res_n = res.shape[0] #should be 25\n",
    "    \n",
    "    second_layer = np.insert(res, res_n, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return second_layer\n",
    "\n",
    "def third_layer (layer, theta):\n",
    "    '''\n",
    "    third layer contains 1 neuron\n",
    "    job is to matmul the second layer's output with theta, apply sigmoid function, and return\n",
    "    \n",
    "    theta is the matrix of size (1, 26)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (1,26)(26,) -> (1,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    return res #should be a singular value answer, our prediction\n",
    "\n",
    "def nn_predict (image, big_theta):\n",
    "    '''\n",
    "    application of all three layers\n",
    "    '''\n",
    "    \n",
    "    #temporary values\n",
    "    theta1, theta2 = turn_one_to_two(big_theta)\n",
    "    \n",
    "    layer1 = first_layer(image)\n",
    "    layer2 = second_layer(layer1, theta1) #this theta value will take on PSO's output once complete\n",
    "    layer3 = third_layer(layer2, theta2)\n",
    "    \n",
    "    return layer3[0] #the prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999998629042793\n"
     ]
    }
   ],
   "source": [
    "#do some testing with values, we should be able to get a value\n",
    "test = images[100]\n",
    "print(nn_predict(test, ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that certainly looks like a value. Good job kense. Time to start PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(big_theta, images, labels):\n",
    "    fitness = 0.0\n",
    "    for k in range(0, len(labels)):\n",
    "        fitness+=(labels[k] - nn_predict(images[k], big_theta))**2\n",
    "    return fitness/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999989841116482\n"
     ]
    }
   ],
   "source": [
    "t1 = np.random.rand(25,401)\n",
    "t2 = np.random.rand(1,26)\n",
    "bt = turn_two_to_one(t1,t2)\n",
    "print(calc_fitness(bt, images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_positions ():\n",
    "    return np.random.rand(25,401), np.random.rand(1,26)\n",
    "\n",
    "def init_velocities ():\n",
    "    return np.zeros((25,401)), np.zeros((1,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO (n, tmax, images, labels):\n",
    "    \n",
    "    #variables\n",
    "    global_best = [None,float('inf')] #global_best is (position, fitness)\n",
    "    inertia_constant = 0.9\n",
    "    c1 = 1.99811 #defined by the assignment as close to 2\n",
    "    c2 = 1.99899\n",
    "    t = 0\n",
    "    vmax = 0.1\n",
    "    \n",
    "    #initialize particles -> (s, v, b)\n",
    "    particles = []\n",
    "    for i in range(n):\n",
    "        s0_a, s0_b = init_positions()\n",
    "        v0_a, v0_b = init_velocities()\n",
    "        \n",
    "        big_s0 = turn_two_to_one(s0_a, s0_b)\n",
    "        big_v0 = turn_two_to_one(v0_a, v0_b)\n",
    "        particle = [big_s0, big_v0, big_s0] #personal_best init is s0\n",
    "        particles.append(particle)\n",
    "   \n",
    "    \n",
    "    while(t < tmax):\n",
    "        \n",
    "        #for each particle\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][0], images, labels) #positions are taken to calc fitness\n",
    "            pbest_fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= pbest_fit: #if better than personal_best\n",
    "                particles[i][2] = particles[i][0][:] #copy as new best\n",
    "        \n",
    "        #set global_best\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= global_best[1]: #if personal_best better than global_best\n",
    "                global_best[1] = fit\n",
    "                global_best[0] = particles[i][2][:] #set new values for global\n",
    "        \n",
    "        #for each particle, update s and v\n",
    "        for i in range(n):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            \n",
    "            #for each particle, update its particles...\n",
    "            for x in range(len(particles[i][1])): #update each particle's v\n",
    "                particles[i][1][x] = (inertia_constant*particles[i][1][x]) + (c1*r1*(particles[i][2][x]-particles[i][0][x])) + (c2*r2*(global_best[0][x]-particles[i][0][x]))\n",
    "                \n",
    "                #velocity cutoff?\n",
    "                if abs(particles[i][1][x]) >= vmax:\n",
    "                    particles[i][1][x] = vmax*np.sign(particles[i][1][x])\n",
    "            \n",
    "            particles[i][0] = np.add(particles[i][0],particles[i][1]) #then update s\n",
    "        \n",
    "        t = t + 1\n",
    "    \n",
    "    #get the stats of the global_best\n",
    "    theta1, theta2 = turn_one_to_two(global_best[0]) #separate global_best's particle into thetas\n",
    "    return theta1, theta2 #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.62540334  0.40188008  0.6676292  ...  0.86780416  0.06229252\n",
      "   0.57421229]\n",
      " [ 0.67978928  1.43511749  0.74373902 ...  0.13808986  0.47693509\n",
      "   0.76451799]\n",
      " [ 1.34501693  1.24706923  1.18222882 ... -0.3194468   0.82453523\n",
      "  -0.09551419]\n",
      " ...\n",
      " [ 0.45521137  0.29096529  0.07029831 ...  0.11565749  1.31537053\n",
      "   0.85751491]\n",
      " [ 1.15394719  0.55019437  0.69938435 ...  0.43845449  0.86570844\n",
      "   0.75616676]\n",
      " [ 0.72485841  0.20208096  0.71372357 ...  0.46375838  0.64965575\n",
      "   0.68656984]] [[ 0.30064832  0.13120119  0.20630518  0.55047572  0.55386252 -0.17248481\n",
      "   0.7775606   1.23056316  0.44249962  0.57575182  0.05165106  1.05959911\n",
      "  -0.15437043  0.27359108 -0.26276193  0.14812417  0.27210154  1.05869465\n",
      "   0.8669225   0.79635301  0.66949638  0.48667493 -0.1469694   0.53541114\n",
      "   1.00008308  0.29145016]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a,b = PSO(3, 10, images, labels)\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#error testing\n",
    "correct = 0\n",
    "predictions = []\n",
    "for i in range(len(images)):\n",
    "    predict = nn_predict(images[i], turn_two_to_one(a,b))\n",
    "    predictions.append(predict)\n",
    "    truth = labels[i]\n",
    "    \n",
    "    if truth == int(predict+0.5):\n",
    "        correct += 1\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999902908719881,\n",
       " 0.9999902908719879,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.999990290871987,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719819,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719863,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.999990290871987,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.999990290871979,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719848,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908708407,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719621,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719877,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719142,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719797,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719845,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719874,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719879,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719879,\n",
       " 0.9999902908719877,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.999990290871987,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719877,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719752,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719879,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719619,\n",
       " 0.9999902908719852,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719834,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.999990290871965,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719703,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719877,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719788,\n",
       " 0.9999902908719881,\n",
       " 0.9999902908719881]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
