{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ning\n",
    "#17 Nov\n",
    "#Metaheuristics TP5\n",
    "\n",
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary look at the X.dat file and Y.dat file\n",
    "#Note that 0 corresponds to 'two' and 1 corresponds to 'three'\n",
    "\n",
    "def transfer_file_to_arrays (filename):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            line = line.split(\",\") #split values on ,\n",
    "            for i in range(0, len(line)):\n",
    "                line[i] = float(line[i]) #turn into a float\n",
    "            line = np.array(line)\n",
    "            images.append(line) #append in np array format\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_labels (filename):\n",
    "    labels = []\n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            labels.append(float(line))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "images = transfer_file_to_arrays(\"X.dat\")\n",
    "print(len(images)) #confirm that we have 200 images stored\n",
    "print(images[0].shape[0]) #confirm the shape of the image\n",
    "labels = get_labels(\"Y.dat\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef2fadb9e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a sample of the image to see if we have one\n",
    "plt.imshow(np.reshape(images[2], (20,20), order=\"F\"), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_two_to_one (theta1, theta2):\n",
    "    return np.concatenate((theta1.flatten(), theta2.flatten()), axis=None)\n",
    "\n",
    "def turn_one_to_two (big_theta):\n",
    "    \n",
    "    theta1 = np.reshape(big_theta[0:10025], (25,401)) #need to be careful here because of shape\n",
    "    theta2 = np.reshape(big_theta[10025:], (1,26))\n",
    "    \n",
    "    return theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a = 6*np.zeros((25,401))-3\n",
    "b = 6*np.full((1,26),1)-3\n",
    "\n",
    "ab = turn_two_to_one(a,b)\n",
    "c,d = turn_one_to_two(ab)\n",
    "\n",
    "print(a==c)\n",
    "print(b==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def first_layer (picture):\n",
    "    '''\n",
    "    first layer's role is to download the 400 pixels of the picture\n",
    "    and have one neuron that is the bias \n",
    "    '''\n",
    "    #add bias neuron\n",
    "    layer_n = picture.shape[0]\n",
    "    first_layer = np.insert(picture, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return first_layer\n",
    "\n",
    "def second_layer (layer, theta):\n",
    "    '''\n",
    "    second layer contains 25 neurons, plus 1 for the bias\n",
    "    job is to matmul the first layer's output with theta, apply sigmoid function, add bias\n",
    "    \n",
    "    theta is the matrix of size (25, 401)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (25,401)(401,) -> (25,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    res_n = res.shape[0] #should be 25\n",
    "    \n",
    "    second_layer = np.insert(res, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return second_layer\n",
    "\n",
    "def third_layer (layer, theta):\n",
    "    '''\n",
    "    third layer contains 1 neuron\n",
    "    job is to matmul the second layer's output with theta, apply sigmoid function, and return\n",
    "    \n",
    "    theta is the matrix of size (1, 26)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (1,26)(26,) -> (1,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    return res #should be a singular value answer, our prediction\n",
    "\n",
    "def nn_predict (image, big_theta):\n",
    "    '''\n",
    "    application of all three layers\n",
    "    '''\n",
    "    \n",
    "    #temporary values\n",
    "    theta1, theta2 = turn_one_to_two(big_theta)\n",
    "    \n",
    "    layer1 = first_layer(image)\n",
    "    layer2 = second_layer(layer1, theta1) #this theta value will take on PSO's output once complete\n",
    "    layer3 = third_layer(layer2, theta2)\n",
    "    \n",
    "    return layer3[0] #the prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525741268224334\n"
     ]
    }
   ],
   "source": [
    "#do some testing with values, we should be able to get a value\n",
    "test = images[2]\n",
    "print(nn_predict(test, ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that certainly looks like a value. Good job kense. Time to start PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(big_theta, images, labels):\n",
    "    fitness = 0.0\n",
    "    for k in range(0, len(labels)):\n",
    "        fitness+=(labels[k] - nn_predict(images[k], big_theta))**2\n",
    "    return fitness/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49999955032243937\n"
     ]
    }
   ],
   "source": [
    "t1 = np.random.rand(25,401)\n",
    "t2 = np.random.rand(1,26)\n",
    "bt = turn_two_to_one(t1,t2)\n",
    "print(calc_fitness(bt, images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_positions ():\n",
    "    return 2*np.random.rand(25,401)-1, 2*np.random.rand(1,26)-1\n",
    "\n",
    "def init_velocities ():\n",
    "    return np.zeros((25,401)), np.zeros((1,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO (n, tmax, images, labels):\n",
    "    \n",
    "    #variables\n",
    "    global_best = [None,float('inf')] #global_best is (position, fitness)\n",
    "    inertia_constant = 0.9\n",
    "    c1 = 1.99811 #defined by the assignment as close to 2\n",
    "    c2 = 1.99899\n",
    "    t = 0\n",
    "    vmax = 0.015\n",
    "    \n",
    "    #initialize particles -> (s, v, b)\n",
    "    particles = []\n",
    "    for i in range(n):\n",
    "        s0_a, s0_b = init_positions()\n",
    "        v0_a, v0_b = init_velocities()\n",
    "        \n",
    "        big_s0 = turn_two_to_one(s0_a, s0_b)\n",
    "        big_v0 = turn_two_to_one(v0_a, v0_b)\n",
    "        particle = [big_s0, big_v0, big_s0] #personal_best init is s0\n",
    "        particles.append(particle)\n",
    "   \n",
    "    \n",
    "    while(t < tmax):\n",
    "        \n",
    "        #for each particle\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][0], images, labels) #positions are taken to calc fitness\n",
    "            pbest_fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= pbest_fit: #if better than personal_best\n",
    "                particles[i][2] = particles[i][0][:] #copy as new best\n",
    "        \n",
    "        #set global_best\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= global_best[1]: #if personal_best better than global_best\n",
    "                global_best[1] = fit\n",
    "                global_best[0] = particles[i][2][:] #set new values for global\n",
    "        \n",
    "        #for each particle, update s and v\n",
    "        for i in range(n):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            \n",
    "            #for each particle, update its particles...\n",
    "            for x in range(len(particles[i][1])): #update each particle's v\n",
    "                particles[i][1][x] = (inertia_constant*particles[i][1][x]) + (c1*r1*(particles[i][2][x]-particles[i][0][x])) + (c2*r2*(global_best[0][x]-particles[i][0][x]))\n",
    "                \n",
    "                #velocity cutoff?\n",
    "                if abs(particles[i][1][x]) >= vmax:\n",
    "                    particles[i][1][x] = vmax*np.sign(particles[i][1][x])\n",
    "            \n",
    "            #particles[i][0] = np.add(particles[i][0],particles[i][1]) #then update s\n",
    "            for x in range(len(particles[i][0])):\n",
    "                particles[i][0][x] = particles[i][0][x] + particles[i][1][x]\n",
    "                \n",
    "                #correct if particle is out of the problem range\n",
    "                if particles[i][0][x] > 1:\n",
    "                    particles[i][0][x] = particles[i][0][x]-(2*(particles[i][0][x]- 1))\n",
    "                elif particles[i][0][x] < -1:\n",
    "                    particles[i][0][x] = particles[i][0][x] + (2*(-1-particles[i][0][x]))\n",
    "                \n",
    "        \n",
    "        t = t + 1\n",
    "    \n",
    "    #get the stats of the global_best\n",
    "    theta1, theta2 = turn_one_to_two(global_best[0]) #separate global_best's particle into thetas\n",
    "    return theta1, theta2 #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3295127   0.21406612  0.00771421 ...  0.99995993  0.2647482\n",
      "  -0.14553244]\n",
      " [ 0.48139067  0.32889793 -0.9999634  ... -0.23382453  0.99999658\n",
      "   0.57220019]\n",
      " [ 0.62631849  0.3422951  -0.58160144 ...  0.18284844  0.26695769\n",
      "  -0.48085509]\n",
      " ...\n",
      " [ 0.13292437  0.01594303 -0.27852383 ... -0.56929989 -0.52981627\n",
      "  -0.33585337]\n",
      " [ 0.11889242 -0.73301057 -0.18312435 ... -0.26541761 -0.27228945\n",
      "  -0.13019358]\n",
      " [-0.1233251  -0.49501808 -0.05144692 ...  0.55886783  0.31116364\n",
      "   0.9114545 ]] [[-0.97300254  0.42951872  0.99999985 -0.28952958 -0.73499469  0.23019052\n",
      "   0.15466653 -0.49547932  0.82678698 -0.41152303 -0.14845732 -0.13561658\n",
      "  -0.30047556 -0.99775014 -0.99999962 -0.60722338  0.99953507 -0.05269004\n",
      "  -0.40442427 -0.81583628  0.76063566 -0.09838725  0.77322562 -0.06674004\n",
      "   0.05971625  0.99999976]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a,b = PSO(10, 200, images, labels)\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785\n"
     ]
    }
   ],
   "source": [
    "#error testing\n",
    "correct = 0\n",
    "predictions = []\n",
    "for i in range(len(images)):\n",
    "    predict = nn_predict(images[i], turn_two_to_one(a,b))\n",
    "    predictions.append(predict)\n",
    "    truth = labels[i]\n",
    "    \n",
    "    if truth == int(predict+0.5):\n",
    "        correct += 1\n",
    "print(correct/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6818596119378255,\n",
       " 0.18315198109914838,\n",
       " 0.284968830572316,\n",
       " 0.23358290373526472,\n",
       " 0.7097851569790743,\n",
       " 0.6746848056641557,\n",
       " 0.34406109547947844,\n",
       " 0.8504675269445285,\n",
       " 0.661070470589681,\n",
       " 0.2999071983295689,\n",
       " 0.5605585561190434,\n",
       " 0.4104353597372886,\n",
       " 0.724428609276207,\n",
       " 0.22665086754893896,\n",
       " 0.6129392867527124,\n",
       " 0.7261789506621835,\n",
       " 0.5928500171262814,\n",
       " 0.7560024140705034,\n",
       " 0.4579903224792445,\n",
       " 0.546339952079649,\n",
       " 0.7878436786340643,\n",
       " 0.6054562667466653,\n",
       " 0.4999761157573643,\n",
       " 0.6283933027649026,\n",
       " 0.692354664855131,\n",
       " 0.18222156365670147,\n",
       " 0.40768253029787277,\n",
       " 0.7560235499689631,\n",
       " 0.4957987040622077,\n",
       " 0.5751528564560293,\n",
       " 0.5508845977007547,\n",
       " 0.5587179773041725,\n",
       " 0.30782725823590723,\n",
       " 0.735033953850671,\n",
       " 0.8529089018844372,\n",
       " 0.42890028495756605,\n",
       " 0.33611782241605537,\n",
       " 0.5251759324316793,\n",
       " 0.7993966994281329,\n",
       " 0.6476227881193465,\n",
       " 0.5366170339859723,\n",
       " 0.7277741539482947,\n",
       " 0.38304497158229345,\n",
       " 0.661045354216642,\n",
       " 0.5904585422540742,\n",
       " 0.681371189810609,\n",
       " 0.869642744888264,\n",
       " 0.44314903814598217,\n",
       " 0.3017176796038511,\n",
       " 0.33852970469869437,\n",
       " 0.6299814584484532,\n",
       " 0.42122061219105833,\n",
       " 0.3803777796229448,\n",
       " 0.6472649760655097,\n",
       " 0.21294596759641005,\n",
       " 0.31528527105989335,\n",
       " 0.3937758613419536,\n",
       " 0.5602455548374817,\n",
       " 0.48242676800670103,\n",
       " 0.7101600035489776,\n",
       " 0.7004445712998683,\n",
       " 0.49503604051517325,\n",
       " 0.3656559672554587,\n",
       " 0.8497083979355678,\n",
       " 0.695991369526612,\n",
       " 0.7016201349969514,\n",
       " 0.5555125712111872,\n",
       " 0.5930599019288342,\n",
       " 0.5795164465841994,\n",
       " 0.4598478932919991,\n",
       " 0.7867138629593587,\n",
       " 0.7254721516591253,\n",
       " 0.4668419857956636,\n",
       " 0.44543311147037484,\n",
       " 0.7994866890488763,\n",
       " 0.6812941559471174,\n",
       " 0.211000179192417,\n",
       " 0.7040496487720425,\n",
       " 0.7809972840512698,\n",
       " 0.21784773469879454,\n",
       " 0.3533745827217414,\n",
       " 0.815579317266936,\n",
       " 0.5560846050416731,\n",
       " 0.6131027590878944,\n",
       " 0.3487101630615159,\n",
       " 0.6778145010843903,\n",
       " 0.7862609458768262,\n",
       " 0.3289377733739545,\n",
       " 0.6342276382023032,\n",
       " 0.4882620493797917,\n",
       " 0.6746693173569761,\n",
       " 0.8381231550197767,\n",
       " 0.347729036615249,\n",
       " 0.24011072014812423,\n",
       " 0.6976711313306142,\n",
       " 0.40832102440567203,\n",
       " 0.3479795196522859,\n",
       " 0.7631828535712702,\n",
       " 0.5387526743705072,\n",
       " 0.6261345526735835,\n",
       " 0.03299431907483818,\n",
       " 0.08277806466751741,\n",
       " 0.07467039471753663,\n",
       " 0.5110838674686362,\n",
       " 0.06516627961833003,\n",
       " 0.33933974950753676,\n",
       " 0.6679382271398911,\n",
       " 0.24409254717404763,\n",
       " 0.04896671140101759,\n",
       " 0.05733419113385162,\n",
       " 0.2458244669261226,\n",
       " 0.26200978533666536,\n",
       " 0.1341213441873994,\n",
       " 0.29631638886892725,\n",
       " 0.45905271736985537,\n",
       " 0.10699947688939057,\n",
       " 0.03718423259959615,\n",
       " 0.4307657019822736,\n",
       " 0.13829399998766845,\n",
       " 0.07931690341980055,\n",
       " 0.2994643591375424,\n",
       " 0.08501364196403607,\n",
       " 0.4725314534171968,\n",
       " 0.08778600289459831,\n",
       " 0.04867458457000123,\n",
       " 0.32504259086217274,\n",
       " 0.06309335321666298,\n",
       " 0.046436626495671166,\n",
       " 0.1728134728965332,\n",
       " 0.25192835073519815,\n",
       " 0.12928127216474164,\n",
       " 0.10349498498110336,\n",
       " 0.05419190006763396,\n",
       " 0.033611738303585874,\n",
       " 0.08151746553515025,\n",
       " 0.23626684844252374,\n",
       " 0.23129311016313925,\n",
       " 0.0692370076432256,\n",
       " 0.3531165793629817,\n",
       " 0.09257407542028068,\n",
       " 0.08434350233867431,\n",
       " 0.1222759799511188,\n",
       " 0.13158977013260087,\n",
       " 0.247840507297554,\n",
       " 0.08317805112078146,\n",
       " 0.07436723681805447,\n",
       " 0.15997106252425852,\n",
       " 0.1751521605763982,\n",
       " 0.13089840219559912,\n",
       " 0.054269572887369825,\n",
       " 0.2465500290287019,\n",
       " 0.1660734835288501,\n",
       " 0.26297847998576107,\n",
       " 0.11188521865780067,\n",
       " 0.13446363721537807,\n",
       " 0.09402721381843168,\n",
       " 0.38320672945570833,\n",
       " 0.05736830752838562,\n",
       " 0.3426820871443777,\n",
       " 0.053377474445154345,\n",
       " 0.18597278999845457,\n",
       " 0.029196958695649953,\n",
       " 0.4558866042852893,\n",
       " 0.07722632772608537,\n",
       " 0.07898711993228383,\n",
       " 0.07643447711268207,\n",
       " 0.0833759996409888,\n",
       " 0.09204962737083111,\n",
       " 0.1103474347174106,\n",
       " 0.12212108832884339,\n",
       " 0.0846655233791588,\n",
       " 0.11884110552914752,\n",
       " 0.1575897946137572,\n",
       " 0.20233046909349753,\n",
       " 0.09968513877689777,\n",
       " 0.13935560866436464,\n",
       " 0.3039103786775682,\n",
       " 0.6369334882741912,\n",
       " 0.04649476705424122,\n",
       " 0.15265518800701242,\n",
       " 0.26704985360661365,\n",
       " 0.24561944874312655,\n",
       " 0.23376217262346358,\n",
       " 0.03499731110301971,\n",
       " 0.31490350705663805,\n",
       " 0.22343318105355897,\n",
       " 0.28661811419273786,\n",
       " 0.254578414594145,\n",
       " 0.26298679249539403,\n",
       " 0.07371063966921525,\n",
       " 0.2321525166894302,\n",
       " 0.031569353218835146,\n",
       " 0.030019859696929538,\n",
       " 0.07655517906580765,\n",
       " 0.09880803535619818,\n",
       " 0.1959946498213527,\n",
       " 0.13684162599634284,\n",
       " 0.05140470978205701,\n",
       " 0.0426879442845521,\n",
       " 0.05579235439567308]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
