{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ning\n",
    "#17 Nov\n",
    "#Metaheuristics TP5\n",
    "\n",
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary look at the X.dat file and Y.dat file\n",
    "#Note that 0 corresponds to 'two' and 1 corresponds to 'three'\n",
    "\n",
    "def transfer_file_to_arrays (filename):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            line = line.split(\",\") #split values on ,\n",
    "            for i in range(0, len(line)):\n",
    "                line[i] = float(line[i]) #turn into a float\n",
    "            line = np.array(line)\n",
    "            images.append(line) #append in np array format\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_labels (filename):\n",
    "    labels = []\n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            labels.append(float(line))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "images = transfer_file_to_arrays(\"X.dat\")\n",
    "print(len(images)) #confirm that we have 200 images stored\n",
    "print(images[0].shape[0]) #confirm the shape of the image\n",
    "labels = get_labels(\"Y.dat\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f44447dfc18>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a sample of the image to see if we have one\n",
    "plt.imshow(np.reshape(images[2], (20,20), order=\"F\"), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_two_to_one (theta1, theta2):\n",
    "    return np.concatenate((theta1.flatten(), theta2.flatten()), axis=None)\n",
    "\n",
    "def turn_one_to_two (big_theta):\n",
    "    \n",
    "    theta1 = np.reshape(big_theta[0:10025], (25,401)) #need to be careful here because of shape\n",
    "    theta2 = np.reshape(big_theta[10025:], (1,26))\n",
    "    \n",
    "    return theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a = np.zeros((25,401))\n",
    "b = np.full((1,26),1)\n",
    "\n",
    "ab = turn_two_to_one(a,b)\n",
    "c,d = turn_one_to_two(ab)\n",
    "\n",
    "print(a==c)\n",
    "print(b==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def first_layer (picture):\n",
    "    '''\n",
    "    first layer's role is to download the 400 pixels of the picture\n",
    "    and have one neuron that is the bias \n",
    "    '''\n",
    "    #add bias neuron\n",
    "    layer_n = picture.shape[0]\n",
    "    first_layer = np.insert(picture, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return first_layer\n",
    "\n",
    "def second_layer (layer, theta):\n",
    "    '''\n",
    "    second layer contains 25 neurons, plus 1 for the bias\n",
    "    job is to matmul the first layer's output with theta, apply sigmoid function, add bias\n",
    "    \n",
    "    theta is the matrix of size (25, 401)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (25,401)(401,) -> (25,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    res_n = res.shape[0] #should be 25\n",
    "    \n",
    "    second_layer = np.insert(res, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return second_layer\n",
    "\n",
    "def third_layer (layer, theta):\n",
    "    '''\n",
    "    third layer contains 1 neuron\n",
    "    job is to matmul the second layer's output with theta, apply sigmoid function, and return\n",
    "    \n",
    "    theta is the matrix of size (1, 26)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (1,26)(26,) -> (1,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    return res #should be a singular value answer, our prediction\n",
    "\n",
    "def nn_predict (image, big_theta):\n",
    "    '''\n",
    "    application of all three layers\n",
    "    '''\n",
    "    \n",
    "    #temporary values\n",
    "    theta1, theta2 = turn_one_to_two(big_theta)\n",
    "    \n",
    "    layer1 = first_layer(image)\n",
    "    layer2 = second_layer(layer1, theta1) #this theta value will take on PSO's output once complete\n",
    "    layer3 = third_layer(layer2, theta2)\n",
    "    \n",
    "    return layer3[0] #the prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999998629042793\n"
     ]
    }
   ],
   "source": [
    "#do some testing with values, we should be able to get a value\n",
    "test = images[100]\n",
    "print(nn_predict(test, ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that certainly looks like a value. Good job kense. Time to start PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(big_theta, images, labels):\n",
    "    fitness = 0.0\n",
    "    for k in range(0, len(labels)):\n",
    "        fitness+=(labels[k] - nn_predict(images[k], big_theta))**2\n",
    "    return fitness/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999969692277524\n"
     ]
    }
   ],
   "source": [
    "t1 = np.random.rand(25,401)\n",
    "t2 = np.random.rand(1,26)\n",
    "bt = turn_two_to_one(t1,t2)\n",
    "print(calc_fitness(bt, images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_positions ():\n",
    "    return np.random.rand(25,401), np.random.rand(1,26)\n",
    "\n",
    "def init_velocities ():\n",
    "    return np.zeros((25,401)), np.zeros((1,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO (n, tmax, images, labels):\n",
    "    \n",
    "    #variables\n",
    "    global_best = [None,float('inf')] #global_best is (position, fitness)\n",
    "    inertia_constant = 0.9\n",
    "    c1 = 1.99811 #defined by the assignment as close to 2\n",
    "    c2 = 1.99899\n",
    "    t = 0\n",
    "    vmax = 0.05\n",
    "    \n",
    "    #initialize particles -> (s, v, b)\n",
    "    particles = []\n",
    "    for i in range(n):\n",
    "        s0_a, s0_b = init_positions()\n",
    "        v0_a, v0_b = init_velocities()\n",
    "        \n",
    "        big_s0 = turn_two_to_one(s0_a, s0_b)\n",
    "        big_v0 = turn_two_to_one(v0_a, v0_b)\n",
    "        particle = [big_s0, big_v0, big_s0] #personal_best init is s0\n",
    "        particles.append(particle)\n",
    "   \n",
    "    \n",
    "    while(t < tmax):\n",
    "        \n",
    "        #for each particle\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][0], images, labels) #positions are taken to calc fitness\n",
    "            pbest_fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= pbest_fit: #if better than personal_best\n",
    "                particles[i][2] = particles[i][0][:] #copy as new best\n",
    "        \n",
    "        #set global_best\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= global_best[1]: #if personal_best better than global_best\n",
    "                global_best[1] = fit\n",
    "                global_best[0] = particles[i][2][:] #set new values for global\n",
    "        \n",
    "        #for each particle, update s and v\n",
    "        for i in range(n):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            \n",
    "            #for each particle, update its particles...\n",
    "            for x in range(len(particles[i][1])): #update each particle's v\n",
    "                particles[i][1][x] = (inertia_constant*particles[i][1][x]) + (c1*r1*(particles[i][2][x]-particles[i][0][x])) + (c2*r2*(global_best[0][x]-particles[i][0][x]))\n",
    "                \n",
    "                #velocity cutoff?\n",
    "                if abs(particles[i][1][x]) >= vmax:\n",
    "                    particles[i][1][x] = vmax*np.sign(particles[i][1][x])\n",
    "            \n",
    "            #particles[i][0] = np.add(particles[i][0],particles[i][1]) #then update s\n",
    "            for x in range(len(particles[i][0])):\n",
    "                particles[i][0][x] = particles[i][0][x] + particles[i][1][x]\n",
    "                \n",
    "                #correct if particle is out of the problem range\n",
    "                if particles[i][0][x] > 1:\n",
    "                    particles[i][0][x] = (particles[i][0][x]-2)*(particles[i][0][x]- 1)\n",
    "                elif particles[i][0][x] < -1:\n",
    "                    particles[i][0][x] = (particles[i][0][x] + 2)*(-1-particles[i][0][x])\n",
    "                \n",
    "        \n",
    "        t = t + 1\n",
    "    \n",
    "    #get the stats of the global_best\n",
    "    theta1, theta2 = turn_one_to_two(global_best[0]) #separate global_best's particle into thetas\n",
    "    return theta1, theta2 #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.92525166 -0.42685122  0.41612684 ... -0.2077722   0.32851931\n",
      "   0.01829133]\n",
      " [ 0.49843738 -0.37388025 -0.08958905 ...  0.05962873  0.07008462\n",
      "  -0.11594189]\n",
      " [-0.41264156  0.81071468  0.63471362 ...  0.29083644 -0.19928463\n",
      "   0.14053128]\n",
      " ...\n",
      " [ 0.11167368  0.08730184 -0.51363631 ... -0.11257682  0.42520349\n",
      "  -0.50201277]\n",
      " [-0.31614947 -0.08205219  0.32205581 ... -0.03295464  0.06644691\n",
      "   0.14429282]\n",
      " [ 0.15578667  0.62712269 -0.54157783 ... -0.01448632 -0.39858187\n",
      "  -0.26643935]] [[-0.19407567 -0.151564    0.03198703  0.1280067  -0.0025737   0.48737146\n",
      "  -0.03525058 -0.01921185  0.05892795  0.30346513  0.25290342 -0.30027171\n",
      "  -0.04725608 -0.22534636  0.24590873  0.34670486 -0.6280711   0.32125405\n",
      "   0.31047273 -0.31604832  0.54518959 -0.42121571 -0.10344596  0.04691075\n",
      "  -0.23946888  0.37369251]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a,b = PSO(5, 50, images, labels)\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#error testing\n",
    "correct = 0\n",
    "predictions = []\n",
    "for i in range(len(images)):\n",
    "    predict = nn_predict(images[i], turn_two_to_one(a,b))\n",
    "    predictions.append(predict)\n",
    "    truth = labels[i]\n",
    "    \n",
    "    if truth == int(predict+0.5):\n",
    "        correct += 1\n",
    "print(correct/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.680064259732548,\n",
       " 0.6704855697774298,\n",
       " 0.6826334164950696,\n",
       " 0.6614827050289654,\n",
       " 0.6829858116919825,\n",
       " 0.6791783678722804,\n",
       " 0.6823244718425187,\n",
       " 0.6808898888004574,\n",
       " 0.683082843561413,\n",
       " 0.6795046703280658,\n",
       " 0.6805244321994773,\n",
       " 0.6814007228546383,\n",
       " 0.6830449126986999,\n",
       " 0.6367767276362641,\n",
       " 0.67146903133943,\n",
       " 0.680457173954215,\n",
       " 0.6832246318261253,\n",
       " 0.6535898990956637,\n",
       " 0.6826180149779973,\n",
       " 0.6651415391741016,\n",
       " 0.6804277856339731,\n",
       " 0.6829597163886565,\n",
       " 0.6830376710473728,\n",
       " 0.6823914327023951,\n",
       " 0.6824139498077382,\n",
       " 0.6831471473805258,\n",
       " 0.680329845826283,\n",
       " 0.6813809242402648,\n",
       " 0.6763519998345608,\n",
       " 0.6773579823532238,\n",
       " 0.6725390827906643,\n",
       " 0.6807362372352918,\n",
       " 0.6809279779325303,\n",
       " 0.6829620034079984,\n",
       " 0.6827901447319417,\n",
       " 0.6828028643651036,\n",
       " 0.679846832971396,\n",
       " 0.6811073569038767,\n",
       " 0.6757196159990012,\n",
       " 0.6647380019703895,\n",
       " 0.6728996394460038,\n",
       " 0.6790087258250349,\n",
       " 0.6830823605899701,\n",
       " 0.6826282438134954,\n",
       " 0.6841957697096704,\n",
       " 0.6829089168245591,\n",
       " 0.6829217068652649,\n",
       " 0.6787475321683617,\n",
       " 0.6817435855067897,\n",
       " 0.6855430869159415,\n",
       " 0.6817575796676624,\n",
       " 0.6822104202758478,\n",
       " 0.6714022280606298,\n",
       " 0.6831461982548754,\n",
       " 0.6828893904788262,\n",
       " 0.6805444114032735,\n",
       " 0.6467686986566825,\n",
       " 0.6660229718060647,\n",
       " 0.6794773647212358,\n",
       " 0.68274584903318,\n",
       " 0.678418998743672,\n",
       " 0.6732134624821378,\n",
       " 0.6806768236435143,\n",
       " 0.6823909342305504,\n",
       " 0.6683765230403038,\n",
       " 0.6830668277903371,\n",
       " 0.6826173115452018,\n",
       " 0.6832974288650665,\n",
       " 0.6811714213053981,\n",
       " 0.6829369858657924,\n",
       " 0.6831887646450351,\n",
       " 0.6772456112994749,\n",
       " 0.6747293451571602,\n",
       " 0.6827183818059055,\n",
       " 0.6817833657812263,\n",
       " 0.6824186669362469,\n",
       " 0.6723562931872125,\n",
       " 0.6819422605366641,\n",
       " 0.6833090691294871,\n",
       " 0.6779336656689218,\n",
       " 0.682257090958939,\n",
       " 0.6829064994681027,\n",
       " 0.6826695240766922,\n",
       " 0.681665584677507,\n",
       " 0.6786854489928663,\n",
       " 0.6822154406435054,\n",
       " 0.6818285010616544,\n",
       " 0.6808443513874344,\n",
       " 0.6801176846181466,\n",
       " 0.6531325768501928,\n",
       " 0.7014736200741879,\n",
       " 0.6791902229655681,\n",
       " 0.6708722465702485,\n",
       " 0.6827115747310002,\n",
       " 0.6828753598098919,\n",
       " 0.6828690802250262,\n",
       " 0.6827430211906643,\n",
       " 0.6745905317201197,\n",
       " 0.6813931818153347,\n",
       " 0.6827566770719821,\n",
       " 0.6789168124137556,\n",
       " 0.6818649095969551,\n",
       " 0.6808669877507673,\n",
       " 0.6816593086153181,\n",
       " 0.6808998473074991,\n",
       " 0.6836790848551959,\n",
       " 0.6801796772464384,\n",
       " 0.6650259145418439,\n",
       " 0.6745608814284451,\n",
       " 0.6742347013080937,\n",
       " 0.6591214059830265,\n",
       " 0.6570482137261583,\n",
       " 0.6809292791345384,\n",
       " 0.678530605002829,\n",
       " 0.6825238695900625,\n",
       " 0.677972096707185,\n",
       " 0.6755986182427629,\n",
       " 0.6718367498853998,\n",
       " 0.6794890970409185,\n",
       " 0.6827220986660153,\n",
       " 0.6811426454511444,\n",
       " 0.6681073687957977,\n",
       " 0.682372773394203,\n",
       " 0.6610543234036896,\n",
       " 0.6789611417657699,\n",
       " 0.6824224257700814,\n",
       " 0.680062016425841,\n",
       " 0.6702075289402946,\n",
       " 0.6699704706319686,\n",
       " 0.678181037969878,\n",
       " 0.6803499810901844,\n",
       " 0.6782651227838917,\n",
       " 0.6672006397530768,\n",
       " 0.6540445200242803,\n",
       " 0.6729322837347461,\n",
       " 0.6765581055966791,\n",
       " 0.66289097724763,\n",
       " 0.672525054619016,\n",
       " 0.6783060399063219,\n",
       " 0.6549745608450175,\n",
       " 0.6755027007039569,\n",
       " 0.6794040593406161,\n",
       " 0.6779989108489322,\n",
       " 0.6817846027624956,\n",
       " 0.6766291380952211,\n",
       " 0.6672958918192581,\n",
       " 0.6801045601450632,\n",
       " 0.6752483477826776,\n",
       " 0.6815296147803015,\n",
       " 0.6651633678182933,\n",
       " 0.6825990642309476,\n",
       " 0.6598715423367498,\n",
       " 0.675336628466368,\n",
       " 0.6741907075573075,\n",
       " 0.6798533091979133,\n",
       " 0.6722285833381546,\n",
       " 0.6821642822489745,\n",
       " 0.6804400002800611,\n",
       " 0.6540998592319792,\n",
       " 0.6626761740655911,\n",
       " 0.6829496203792503,\n",
       " 0.671389181338915,\n",
       " 0.6779554506444059,\n",
       " 0.6768552308300272,\n",
       " 0.6776332308276173,\n",
       " 0.6694145346795406,\n",
       " 0.6733221389200909,\n",
       " 0.6698195230280627,\n",
       " 0.682146231716096,\n",
       " 0.6616757394827246,\n",
       " 0.6773789860763272,\n",
       " 0.6749346738628945,\n",
       " 0.6644432880280078,\n",
       " 0.6810669673464093,\n",
       " 0.6821789685777698,\n",
       " 0.6802796109143561,\n",
       " 0.6798946281072217,\n",
       " 0.6822238045099805,\n",
       " 0.6726943755705704,\n",
       " 0.6823532231411449,\n",
       " 0.6705190179717763,\n",
       " 0.6498159106092273,\n",
       " 0.6808262011189672,\n",
       " 0.6594320268966164,\n",
       " 0.6795779739506004,\n",
       " 0.6054891452350987,\n",
       " 0.6796093624910606,\n",
       " 0.6804585171683561,\n",
       " 0.6719302208188415,\n",
       " 0.6808366909217196,\n",
       " 0.6813244568813762,\n",
       " 0.6700828384520848,\n",
       " 0.6765665806962273,\n",
       " 0.6579903734214189,\n",
       " 0.6784278992353823,\n",
       " 0.6813228981419364,\n",
       " 0.6771275994170525,\n",
       " 0.6423194123569259,\n",
       " 0.6700057196633894,\n",
       " 0.675453219355758]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
