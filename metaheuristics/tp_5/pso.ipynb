{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ning\n",
    "#17 Nov\n",
    "#Metaheuristics TP5\n",
    "\n",
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary look at the X.dat file and Y.dat file\n",
    "#Note that 0 corresponds to 'two' and 1 corresponds to 'three'\n",
    "\n",
    "def transfer_file_to_arrays (filename):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            line = line.split(\",\") #split values on ,\n",
    "            for i in range(0, len(line)):\n",
    "                line[i] = float(line[i]) #turn into a float\n",
    "            line = np.array(line)\n",
    "            images.append(line) #append in np array format\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_labels (filename):\n",
    "    labels = []\n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            labels.append(float(line))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "images = transfer_file_to_arrays(\"X.dat\")\n",
    "print(len(images)) #confirm that we have 200 images stored\n",
    "print(images[0].shape[0]) #confirm the shape of the image\n",
    "labels = get_labels(\"Y.dat\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f44447dfc18>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a sample of the image to see if we have one\n",
    "plt.imshow(np.reshape(images[2], (20,20), order=\"F\"), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_two_to_one (theta1, theta2):\n",
    "    return np.concatenate((theta1.flatten(), theta2.flatten()), axis=None)\n",
    "\n",
    "def turn_one_to_two (big_theta):\n",
    "    \n",
    "    theta1 = np.reshape(big_theta[0:10025], (25,401)) #need to be careful here because of shape\n",
    "    theta2 = np.reshape(big_theta[10025:], (1,26))\n",
    "    \n",
    "    return theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a = np.zeros((25,401))\n",
    "b = np.full((1,26),1)\n",
    "\n",
    "ab = turn_two_to_one(a,b)\n",
    "c,d = turn_one_to_two(ab)\n",
    "\n",
    "print(a==c)\n",
    "print(b==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def first_layer (picture):\n",
    "    '''\n",
    "    first layer's role is to download the 400 pixels of the picture\n",
    "    and have one neuron that is the bias \n",
    "    '''\n",
    "    #add bias neuron\n",
    "    layer_n = picture.shape[0]\n",
    "    first_layer = np.insert(picture, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return first_layer\n",
    "\n",
    "def second_layer (layer, theta):\n",
    "    '''\n",
    "    second layer contains 25 neurons, plus 1 for the bias\n",
    "    job is to matmul the first layer's output with theta, apply sigmoid function, add bias\n",
    "    \n",
    "    theta is the matrix of size (25, 401)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (25,401)(401,) -> (25,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    res_n = res.shape[0] #should be 25\n",
    "    \n",
    "    second_layer = np.insert(res, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return second_layer\n",
    "\n",
    "def third_layer (layer, theta):\n",
    "    '''\n",
    "    third layer contains 1 neuron\n",
    "    job is to matmul the second layer's output with theta, apply sigmoid function, and return\n",
    "    \n",
    "    theta is the matrix of size (1, 26)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (1,26)(26,) -> (1,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    return res #should be a singular value answer, our prediction\n",
    "\n",
    "def nn_predict (image, big_theta):\n",
    "    '''\n",
    "    application of all three layers\n",
    "    '''\n",
    "    \n",
    "    #temporary values\n",
    "    theta1, theta2 = turn_one_to_two(big_theta)\n",
    "    \n",
    "    layer1 = first_layer(image)\n",
    "    layer2 = second_layer(layer1, theta1) #this theta value will take on PSO's output once complete\n",
    "    layer3 = third_layer(layer2, theta2)\n",
    "    \n",
    "    return layer3[0] #the prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999998629042793\n"
     ]
    }
   ],
   "source": [
    "#do some testing with values, we should be able to get a value\n",
    "test = images[100]\n",
    "print(nn_predict(test, ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that certainly looks like a value. Good job kense. Time to start PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(big_theta, images, labels):\n",
    "    fitness = 0.0\n",
    "    for k in range(0, len(labels)):\n",
    "        fitness+=(labels[k] - nn_predict(images[k], big_theta))**2\n",
    "    return fitness/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999969692277524\n"
     ]
    }
   ],
   "source": [
    "t1 = np.random.rand(25,401)\n",
    "t2 = np.random.rand(1,26)\n",
    "bt = turn_two_to_one(t1,t2)\n",
    "print(calc_fitness(bt, images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_positions ():\n",
    "    return 2*np.random.rand(25,401)-1, 2*np.random.rand(1,26)-1\n",
    "\n",
    "def init_velocities ():\n",
    "    return np.zeros((25,401)), np.zeros((1,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO (n, tmax, images, labels):\n",
    "    \n",
    "    #variables\n",
    "    global_best = [None,float('inf')] #global_best is (position, fitness)\n",
    "    inertia_constant = 0.9\n",
    "    c1 = 1.99811 #defined by the assignment as close to 2\n",
    "    c2 = 1.99899\n",
    "    t = 0\n",
    "    vmax = 0.05\n",
    "    \n",
    "    #initialize particles -> (s, v, b)\n",
    "    particles = []\n",
    "    for i in range(n):\n",
    "        s0_a, s0_b = init_positions()\n",
    "        v0_a, v0_b = init_velocities()\n",
    "        \n",
    "        big_s0 = turn_two_to_one(s0_a, s0_b)\n",
    "        big_v0 = turn_two_to_one(v0_a, v0_b)\n",
    "        particle = [big_s0, big_v0, big_s0] #personal_best init is s0\n",
    "        particles.append(particle)\n",
    "   \n",
    "    \n",
    "    while(t < tmax):\n",
    "        \n",
    "        #for each particle\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][0], images, labels) #positions are taken to calc fitness\n",
    "            pbest_fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= pbest_fit: #if better than personal_best\n",
    "                particles[i][2] = particles[i][0][:] #copy as new best\n",
    "        \n",
    "        #set global_best\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= global_best[1]: #if personal_best better than global_best\n",
    "                global_best[1] = fit\n",
    "                global_best[0] = particles[i][2][:] #set new values for global\n",
    "        \n",
    "        #for each particle, update s and v\n",
    "        for i in range(n):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            \n",
    "            #for each particle, update its particles...\n",
    "            for x in range(len(particles[i][1])): #update each particle's v\n",
    "                particles[i][1][x] = (inertia_constant*particles[i][1][x]) + (c1*r1*(particles[i][2][x]-particles[i][0][x])) + (c2*r2*(global_best[0][x]-particles[i][0][x]))\n",
    "                \n",
    "                #velocity cutoff?\n",
    "                if abs(particles[i][1][x]) >= vmax:\n",
    "                    particles[i][1][x] = vmax*np.sign(particles[i][1][x])\n",
    "            \n",
    "            #particles[i][0] = np.add(particles[i][0],particles[i][1]) #then update s\n",
    "            for x in range(len(particles[i][0])):\n",
    "                particles[i][0][x] = particles[i][0][x] + particles[i][1][x]\n",
    "                \n",
    "                #correct if particle is out of the problem range\n",
    "                if particles[i][0][x] > 1:\n",
    "                    particles[i][0][x] = particles[i][0][x]-(2*(particles[i][0][x]- 1))\n",
    "                elif particles[i][0][x] < -1:\n",
    "                    particles[i][0][x] = particles[i][0][x] + (2*(-1-particles[i][0][x]))\n",
    "                \n",
    "        \n",
    "        t = t + 1\n",
    "    \n",
    "    #get the stats of the global_best\n",
    "    theta1, theta2 = turn_one_to_two(global_best[0]) #separate global_best's particle into thetas\n",
    "    return theta1, theta2 #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04141911 -0.53643061  0.02575446 ...  0.05496644 -0.48273897\n",
      "   0.27185117]\n",
      " [-0.03324281  0.13415471 -0.64018736 ...  0.12325364 -0.23436656\n",
      "  -0.13798685]\n",
      " [-0.130798   -0.06523637 -0.42358662 ... -0.06189853  0.00363489\n",
      "  -0.17208476]\n",
      " ...\n",
      " [ 0.26782552  0.67201824  0.06562993 ... -0.0610091   0.2340046\n",
      "   0.08098528]\n",
      " [ 0.17860071 -0.62324057  0.84422582 ... -0.56425406 -0.23664832\n",
      "  -0.98791353]\n",
      " [-0.12413034  0.5171035   0.03157963 ...  0.15973427  0.35942485\n",
      "   0.09072313]] [[ 0.55477047 -0.43116453 -0.23016835  0.08320026  0.97803995 -0.99294717\n",
      "   0.13626557  0.36809108 -0.17642579 -0.07138712 -0.25219757  0.11077588\n",
      "   0.28401625 -0.48052093 -0.11882789  0.96642528 -0.38514145  0.06427776\n",
      "  -0.24786217  0.12248093  0.08128845  0.42933466 -0.50702913 -0.34998308\n",
      "   0.49468392 -0.09460695]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a,b = PSO(5, 20, images, labels)\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715\n"
     ]
    }
   ],
   "source": [
    "#error testing\n",
    "correct = 0\n",
    "predictions = []\n",
    "for i in range(len(images)):\n",
    "    predict = nn_predict(images[i], turn_two_to_one(a,b))\n",
    "    predictions.append(predict)\n",
    "    truth = labels[i]\n",
    "    \n",
    "    if truth == int(predict+0.5):\n",
    "        correct += 1\n",
    "print(correct/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7941702321140182,\n",
       " 0.5496741286567786,\n",
       " 0.6347881811581434,\n",
       " 0.5349793807406592,\n",
       " 0.7533565427346098,\n",
       " 0.42890487021680307,\n",
       " 0.7805369590005011,\n",
       " 0.686055543110346,\n",
       " 0.7678923215089899,\n",
       " 0.7415807339492052,\n",
       " 0.7899601314895636,\n",
       " 0.6889975794604275,\n",
       " 0.6055071250017511,\n",
       " 0.44757207313709857,\n",
       " 0.7232879212114776,\n",
       " 0.6470529489481702,\n",
       " 0.7464773182670105,\n",
       " 0.4222960678905817,\n",
       " 0.7318695812558157,\n",
       " 0.6388449959119994,\n",
       " 0.7072660073970587,\n",
       " 0.7565331294908266,\n",
       " 0.6239371630988294,\n",
       " 0.7214813315938545,\n",
       " 0.5366718452722409,\n",
       " 0.49409167073405696,\n",
       " 0.5693773717647526,\n",
       " 0.6709575954574932,\n",
       " 0.6898721363844141,\n",
       " 0.867003697108024,\n",
       " 0.46644563771210457,\n",
       " 0.8077022241169072,\n",
       " 0.7577601109381138,\n",
       " 0.6606331878060685,\n",
       " 0.5528599490757657,\n",
       " 0.8004928415861932,\n",
       " 0.5074331226917808,\n",
       " 0.7986568037604634,\n",
       " 0.46870492536452885,\n",
       " 0.534631857952044,\n",
       " 0.7644832515110833,\n",
       " 0.7092792831127741,\n",
       " 0.70829256125848,\n",
       " 0.7377550960886142,\n",
       " 0.6955197568378562,\n",
       " 0.6609570362608779,\n",
       " 0.6541820307186983,\n",
       " 0.5843130749988231,\n",
       " 0.6069837115495398,\n",
       " 0.7491838828613382,\n",
       " 0.7710563576126362,\n",
       " 0.7298823042241795,\n",
       " 0.5311533443963168,\n",
       " 0.7228199520909948,\n",
       " 0.5970126201480281,\n",
       " 0.583933309157631,\n",
       " 0.8256424397471761,\n",
       " 0.7016946779543758,\n",
       " 0.7316520490107978,\n",
       " 0.704048778975418,\n",
       " 0.6467531552083717,\n",
       " 0.7500181442663248,\n",
       " 0.6068052789981931,\n",
       " 0.6261228505318733,\n",
       " 0.6790490623087073,\n",
       " 0.7556077926069094,\n",
       " 0.6882697755467995,\n",
       " 0.6988664902110168,\n",
       " 0.7573311979687712,\n",
       " 0.706589447874125,\n",
       " 0.6399065360596515,\n",
       " 0.6344812316247175,\n",
       " 0.5357522116894372,\n",
       " 0.6425301605990885,\n",
       " 0.6919427776449811,\n",
       " 0.6820619724379525,\n",
       " 0.6739805017546205,\n",
       " 0.7939338133277156,\n",
       " 0.6905599495071609,\n",
       " 0.6327999580961908,\n",
       " 0.6312457036101746,\n",
       " 0.6005221015089485,\n",
       " 0.7470156863750369,\n",
       " 0.690476204821978,\n",
       " 0.866755705185134,\n",
       " 0.7448046076262376,\n",
       " 0.5974181266484233,\n",
       " 0.5250401426152609,\n",
       " 0.6611503142624298,\n",
       " 0.7977078399089318,\n",
       " 0.5047042389255194,\n",
       " 0.7481565811857958,\n",
       " 0.6244178196724918,\n",
       " 0.6978636355384149,\n",
       " 0.715100198882595,\n",
       " 0.5776621071238118,\n",
       " 0.371772660121537,\n",
       " 0.47873238596722417,\n",
       " 0.4942194779084545,\n",
       " 0.646881251571132,\n",
       " 0.5881518805148949,\n",
       " 0.5311115936044142,\n",
       " 0.46919895511319043,\n",
       " 0.5894408669595651,\n",
       " 0.6765886992144061,\n",
       " 0.6335373735458166,\n",
       " 0.7489849059440172,\n",
       " 0.34767065748679177,\n",
       " 0.4814820996231081,\n",
       " 0.38060835553254097,\n",
       " 0.4503072549938478,\n",
       " 0.5542444006854554,\n",
       " 0.4064227306975221,\n",
       " 0.46311433369067123,\n",
       " 0.5596786172112644,\n",
       " 0.2800000755033095,\n",
       " 0.3825028857606447,\n",
       " 0.5473277841248677,\n",
       " 0.6968043637779818,\n",
       " 0.5713309975202924,\n",
       " 0.487174444865534,\n",
       " 0.7015961065640814,\n",
       " 0.654601412541154,\n",
       " 0.42543233216349513,\n",
       " 0.5705973901656288,\n",
       " 0.5082460641154967,\n",
       " 0.3850987230620008,\n",
       " 0.4227527767115388,\n",
       " 0.5215667104844164,\n",
       " 0.6512489143682314,\n",
       " 0.6526813494519654,\n",
       " 0.5456264445333184,\n",
       " 0.5355518227329087,\n",
       " 0.4148151782939563,\n",
       " 0.3593189442528253,\n",
       " 0.36942574957841806,\n",
       " 0.4121723401973781,\n",
       " 0.4276875226028038,\n",
       " 0.5266687878965954,\n",
       " 0.5451211747938451,\n",
       " 0.40063158331969634,\n",
       " 0.5268409873619528,\n",
       " 0.4047852083714739,\n",
       " 0.4853783001750412,\n",
       " 0.5704173794209942,\n",
       " 0.7410864447925897,\n",
       " 0.5528260570786678,\n",
       " 0.36618117403291905,\n",
       " 0.6131290388631689,\n",
       " 0.3705358676674196,\n",
       " 0.31425749534342406,\n",
       " 0.323866435107962,\n",
       " 0.4387918848948512,\n",
       " 0.621742319576552,\n",
       " 0.5807426949048354,\n",
       " 0.38217267013174666,\n",
       " 0.6354259334518896,\n",
       " 0.41469474985142574,\n",
       " 0.6482028967732681,\n",
       " 0.4482081880997783,\n",
       " 0.5783181872599465,\n",
       " 0.6183250829864178,\n",
       " 0.5840412719017967,\n",
       " 0.41764219125692553,\n",
       " 0.4851102382183976,\n",
       " 0.5937261582546414,\n",
       " 0.46456083950918736,\n",
       " 0.6216255399798052,\n",
       " 0.331116764966965,\n",
       " 0.5154671092949654,\n",
       " 0.4997603176094494,\n",
       " 0.43382940049609625,\n",
       " 0.5045214317769647,\n",
       " 0.449017799235882,\n",
       " 0.40339653300996886,\n",
       " 0.5662075306371875,\n",
       " 0.4297639734684671,\n",
       " 0.8130998567254465,\n",
       " 0.4718543002803504,\n",
       " 0.6017685298503598,\n",
       " 0.6690194204898262,\n",
       " 0.7654333714734771,\n",
       " 0.4546478811638098,\n",
       " 0.4738263476484629,\n",
       " 0.3082418496872735,\n",
       " 0.4114734194787168,\n",
       " 0.5316187216212137,\n",
       " 0.5096409644822707,\n",
       " 0.4181651397470455,\n",
       " 0.30789890093980254,\n",
       " 0.4743346991142698,\n",
       " 0.6006537230541944,\n",
       " 0.3370569203330985,\n",
       " 0.36670908455316265,\n",
       " 0.49952254617515685,\n",
       " 0.4328335418002783,\n",
       " 0.5304226248788655,\n",
       " 0.41979583090639694,\n",
       " 0.5589151497602216,\n",
       " 0.3141684296327824]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
