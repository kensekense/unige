{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ning\n",
    "#17 Nov\n",
    "#Metaheuristics TP5\n",
    "\n",
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary look at the X.dat file and Y.dat file\n",
    "#Note that 0 corresponds to 'two' and 1 corresponds to 'three'\n",
    "\n",
    "def transfer_file_to_arrays (filename):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            line = line.split(\",\") #split values on ,\n",
    "            for i in range(0, len(line)):\n",
    "                line[i] = float(line[i]) #turn into a float\n",
    "            line = np.array(line)\n",
    "            images.append(line) #append in np array format\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_labels (filename):\n",
    "    labels = []\n",
    "    with open(filename, \"r\") as fp:\n",
    "        for line in fp:\n",
    "            labels.append(float(line))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "images = transfer_file_to_arrays(\"X.dat\")\n",
    "print(len(images)) #confirm that we have 200 images stored\n",
    "print(images[0].shape[0]) #confirm the shape of the image\n",
    "labels = get_labels(\"Y.dat\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc8ab9f5358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a sample of the image to see if we have one\n",
    "plt.imshow(np.reshape(images[2], (20,20), order=\"F\"), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_two_to_one (theta1, theta2):\n",
    "    return np.concatenate((theta1.flatten(), theta2.flatten()), axis=None)\n",
    "\n",
    "def turn_one_to_two (big_theta):\n",
    "    \n",
    "    theta1 = np.reshape(big_theta[0:10025], (25,401)) #need to be careful here because of shape\n",
    "    theta2 = np.reshape(big_theta[10025:], (1,26))\n",
    "    \n",
    "    return theta1, theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " ...\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]\n",
      " [ True  True  True ...  True  True  True]]\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True  True  True  True  True  True  True  True  True  True  True\n",
      "   True  True]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a = 6*np.zeros((25,401))-3\n",
    "b = 6*np.full((1,26),1)-3\n",
    "\n",
    "ab = turn_two_to_one(a,b)\n",
    "c,d = turn_one_to_two(ab)\n",
    "\n",
    "print(a==c)\n",
    "print(b==d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "def first_layer (picture):\n",
    "    '''\n",
    "    first layer's role is to download the 400 pixels of the picture\n",
    "    and have one neuron that is the bias \n",
    "    '''\n",
    "    #add bias neuron\n",
    "    layer_n = picture.shape[0]\n",
    "    first_layer = np.insert(picture, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return first_layer\n",
    "\n",
    "def second_layer (layer, theta):\n",
    "    '''\n",
    "    second layer contains 25 neurons, plus 1 for the bias\n",
    "    job is to matmul the first layer's output with theta, apply sigmoid function, add bias\n",
    "    \n",
    "    theta is the matrix of size (25, 401)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (25,401)(401,) -> (25,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    res_n = res.shape[0] #should be 25\n",
    "    \n",
    "    second_layer = np.insert(res, 0, 1.0) #add 1 as the bias\n",
    "    \n",
    "    return second_layer\n",
    "\n",
    "def third_layer (layer, theta):\n",
    "    '''\n",
    "    third layer contains 1 neuron\n",
    "    job is to matmul the second layer's output with theta, apply sigmoid function, and return\n",
    "    \n",
    "    theta is the matrix of size (1, 26)\n",
    "    '''\n",
    "    \n",
    "    res = np.matmul(theta, layer) #should be a matmul of sizes (1,26)(26,) -> (1,)\n",
    "    \n",
    "    #apply the sigmoid function\n",
    "    res = sigmoid(res)\n",
    "    \n",
    "    return res #should be a singular value answer, our prediction\n",
    "\n",
    "def nn_predict (image, big_theta):\n",
    "    '''\n",
    "    application of all three layers\n",
    "    '''\n",
    "    \n",
    "    #temporary values\n",
    "    theta1, theta2 = turn_one_to_two(big_theta)\n",
    "    \n",
    "    layer1 = first_layer(image)\n",
    "    layer2 = second_layer(layer1, theta1) #this theta value will take on PSO's output once complete\n",
    "    layer3 = third_layer(layer2, theta2)\n",
    "    \n",
    "    return layer3[0] #the prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9525741268224334\n"
     ]
    }
   ],
   "source": [
    "#do some testing with values, we should be able to get a value\n",
    "test = images[2]\n",
    "print(nn_predict(test, ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that certainly looks like a value. Good job kense. Time to start PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fitness(big_theta, images, labels):\n",
    "    fitness = 0.0\n",
    "    for k in range(0, len(labels)):\n",
    "        fitness+=(labels[k] - nn_predict(images[k], big_theta))**2\n",
    "    return fitness/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4999998358959644\n"
     ]
    }
   ],
   "source": [
    "t1 = np.random.rand(25,401)\n",
    "t2 = np.random.rand(1,26)\n",
    "bt = turn_two_to_one(t1,t2)\n",
    "print(calc_fitness(bt, images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_positions ():\n",
    "    return 2*np.random.rand(25,401)-1, 2*np.random.rand(1,26)-1\n",
    "\n",
    "def init_velocities ():\n",
    "    return np.zeros((25,401)), np.zeros((1,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSO (n, tmax, images, labels):\n",
    "    \n",
    "    #variables\n",
    "    global_best = np.array([None,float('inf')]) #global_best is (position, fitness)\n",
    "    inertia_constant = 0.9\n",
    "    c1 = 1.99811 #defined by the assignment as close to 2\n",
    "    c2 = 1.99899\n",
    "    t = 0\n",
    "    vmax = 0.1\n",
    "    \n",
    "    #initialize particles -> (s, v, b)\n",
    "    particles = []\n",
    "    for i in range(n):\n",
    "        s0_a, s0_b = init_positions()\n",
    "        v0_a, v0_b = init_velocities()\n",
    "        \n",
    "        big_s0 = turn_two_to_one(s0_a, s0_b)\n",
    "        big_v0 = turn_two_to_one(v0_a, v0_b)\n",
    "        particle = np.array([big_s0, big_v0, big_s0]) #personal_best init is s0\n",
    "        particles.append(particle)\n",
    "   \n",
    "    \n",
    "    while(t < tmax):\n",
    "        \n",
    "        #for each particle\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][0], images, labels) #positions are taken to calc fitness\n",
    "            pbest_fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= pbest_fit: #if better than personal_best\n",
    "                particles[i][2] = particles[i][0][:] #copy as new best\n",
    "                \n",
    "        #set global_best\n",
    "        for i in range(n):\n",
    "            fit = calc_fitness(particles[i][2], images, labels)\n",
    "            if fit <= global_best[1]: #if personal_best better than global_best\n",
    "                global_best[1] = fit\n",
    "                global_best[0] = particles[i][2][:] #set new values for global\n",
    "        \n",
    "        #particle updates\n",
    "        for i in range(n):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            \n",
    "            #update velocity\n",
    "            particles[i][1] = inertia_constant*particles[i][1] + c1*r1*(particles[i][2]-particles[i][0]) + c2*r2*(global_best[0]-particles[i][0])\n",
    "        \n",
    "            #velocity cutoff?\n",
    "            particles[i][1][particles[i][1] > vmax] = vmax\n",
    "            particles[i][1][particles[i][1] < -1*vmax] = -1*vmax\n",
    "        \n",
    "            #update positions\n",
    "            particles[i][0] = particles[i][0] + particles[i][1]\n",
    "            \n",
    "            #correct particles out of range\n",
    "            for x in range(len(particles[i][0])):\n",
    "                particles[i][0][x] -(2*(particles[i][0][x]-1))\n",
    "                particles[i][0][x] + (2*-1-particles[i][0][x])\n",
    "        \n",
    "        t = t + 1\n",
    "    \n",
    "    #get the stats of the global_best\n",
    "    theta1, theta2 = turn_one_to_two(global_best[0]) #separate global_best's particle into thetas\n",
    "    return theta1, theta2 #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.87902956  0.41202784  0.06868326 ...  1.44360784 -2.15932056\n",
      "  -0.11701099]\n",
      " [ 0.9574316  -0.37029124  1.60767811 ...  1.60610327 -1.68633113\n",
      "   1.65745898]\n",
      " [ 0.47258422  0.13568021 -0.71246439 ... -0.3049891  -0.08645079\n",
      "   0.87158971]\n",
      " ...\n",
      " [ 1.83645446 -0.47021768 -0.47308597 ... -0.82817597  1.10459575\n",
      "  -0.30783993]\n",
      " [-1.51451409 -0.29733571  0.77637438 ... -0.06315916 -0.84548599\n",
      "   0.93269368]\n",
      " [-1.50482059 -0.46426116 -0.17088569 ...  1.19058158  0.46199736\n",
      "   0.18259523]] [[ 0.56477558  0.65951498 -1.71828831  1.26080937 -0.17507657 -0.4533073\n",
      "  -1.40591522 -1.42576633 -0.40503156 -2.59593694  0.67676166 -1.57900269\n",
      "   1.01135022  2.05587701 -1.62656702  1.56758066 -0.25852327  2.15111362\n",
      "  -1.9664551  -2.75574439 -0.53395857 -2.02269056  2.39411503 -0.36264384\n",
      "  -1.71959399 -0.11439152]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "a,b = PSO(20, 200, images, labels)\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n"
     ]
    }
   ],
   "source": [
    "#error testing\n",
    "correct = 0\n",
    "predictions = []\n",
    "for i in range(len(images)):\n",
    "    predict = nn_predict(images[i], turn_two_to_one(a,b))\n",
    "    predictions.append(predict)\n",
    "    truth = labels[i]\n",
    "    \n",
    "    if truth == int(predict+0.5):\n",
    "        correct += 1\n",
    "print(correct/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9883285611461192,\n",
       " 0.8093317168768582,\n",
       " 0.9216042099190888,\n",
       " 0.9087142775899818,\n",
       " 0.9979610822664693,\n",
       " 0.9915030577812324,\n",
       " 0.9925601124431268,\n",
       " 0.9968913456023422,\n",
       " 0.9998960623391279,\n",
       " 0.9558855039626178,\n",
       " 0.9788660700983982,\n",
       " 0.9997018530140812,\n",
       " 0.9997392510268223,\n",
       " 0.9324620226490292,\n",
       " 0.9851958992109613,\n",
       " 0.9689261711643419,\n",
       " 0.9999558354410766,\n",
       " 0.9454456683419136,\n",
       " 0.9925931075546288,\n",
       " 0.9685033954038469,\n",
       " 0.9964368745811256,\n",
       " 0.999975497560237,\n",
       " 0.9988716523018145,\n",
       " 0.9994882489089291,\n",
       " 0.9960638290674119,\n",
       " 0.9531249861443079,\n",
       " 0.9687173592162518,\n",
       " 0.9992534672639661,\n",
       " 0.9971505838170748,\n",
       " 0.9813975608508125,\n",
       " 0.9262764549950957,\n",
       " 0.9959743816670458,\n",
       " 0.986877813030776,\n",
       " 0.9944446634194941,\n",
       " 0.9847257744167874,\n",
       " 0.999686167111452,\n",
       " 0.9974338882802765,\n",
       " 0.9980378499910997,\n",
       " 0.9949217680884017,\n",
       " 0.9523672683071974,\n",
       " 0.9961118847934669,\n",
       " 0.9991166617701817,\n",
       " 0.9976476901327298,\n",
       " 0.9999391287401034,\n",
       " 0.9999188865956438,\n",
       " 0.9992704555479709,\n",
       " 0.9999120836950681,\n",
       " 0.9984087205305884,\n",
       " 0.9567169505905693,\n",
       " 0.9840779169481673,\n",
       " 0.9994939173181829,\n",
       " 0.9984243070641748,\n",
       " 0.9827423909266034,\n",
       " 0.9999573612781123,\n",
       " 0.9987363957492231,\n",
       " 0.988541469792587,\n",
       " 0.904905954277296,\n",
       " 0.9747382610698878,\n",
       " 0.9981726441994048,\n",
       " 0.9981052109925797,\n",
       " 0.9992142179348913,\n",
       " 0.9925758420042194,\n",
       " 0.9924678548124394,\n",
       " 0.9883467720483826,\n",
       " 0.9510326081638993,\n",
       " 0.9993872076729609,\n",
       " 0.9894128720397193,\n",
       " 0.9999752097918303,\n",
       " 0.9981617914831137,\n",
       " 0.9935363916012557,\n",
       " 0.9955456688098736,\n",
       " 0.9982410655462279,\n",
       " 0.9929444495956599,\n",
       " 0.9678969756077656,\n",
       " 0.9966093515321949,\n",
       " 0.9999575426335184,\n",
       " 0.9718879896458409,\n",
       " 0.9947450461849586,\n",
       " 0.9946021478542032,\n",
       " 0.9131804328446493,\n",
       " 0.9997605276282743,\n",
       " 0.9875559630391688,\n",
       " 0.9984001213840508,\n",
       " 0.998056549715718,\n",
       " 0.9937744542964458,\n",
       " 0.997861660340237,\n",
       " 0.781258554040474,\n",
       " 0.9501406366813656,\n",
       " 0.9930878745698158,\n",
       " 0.9813508213497123,\n",
       " 0.9683447677992894,\n",
       " 0.9984402456863606,\n",
       " 0.9598913207023224,\n",
       " 0.9995637587446109,\n",
       " 0.9991976710320846,\n",
       " 0.9898721308544699,\n",
       " 0.9232642810964585,\n",
       " 0.9989743619342404,\n",
       " 0.9888710935563242,\n",
       " 0.9999448408756052,\n",
       " 0.0003962498353491572,\n",
       " 0.0006699711618002735,\n",
       " 0.04149025528045571,\n",
       " 0.0269174426975046,\n",
       " 0.00028346026869649786,\n",
       " 0.0030511777956056733,\n",
       " 0.14269513012800378,\n",
       " 0.034176344292805465,\n",
       " 6.910579750670348e-05,\n",
       " 0.0001313192978752822,\n",
       " 0.007747229752872274,\n",
       " 0.10484292877228495,\n",
       " 0.07483742786012192,\n",
       " 0.004731735599451424,\n",
       " 0.004592250454307671,\n",
       " 0.018027377736374247,\n",
       " 0.004105916919253053,\n",
       " 0.07143844266178781,\n",
       " 0.0012412266830070155,\n",
       " 0.0019692392486552347,\n",
       " 0.012500250893142564,\n",
       " 0.00032855650224027474,\n",
       " 0.9568274666933051,\n",
       " 0.0014630934904930704,\n",
       " 4.901988214656992e-06,\n",
       " 0.002932810340532178,\n",
       " 0.00022909582578114115,\n",
       " 0.0002507711915566538,\n",
       " 0.00014614042363166377,\n",
       " 0.016827448286369055,\n",
       " 0.005348144330928793,\n",
       " 0.0002794205019273554,\n",
       " 2.996576659271614e-05,\n",
       " 0.0014782778129546863,\n",
       " 0.00013301937322319568,\n",
       " 0.0008049816009199321,\n",
       " 0.008478308497622747,\n",
       " 6.202298729304079e-05,\n",
       " 0.11575292929832784,\n",
       " 0.0012861830088029733,\n",
       " 0.0014406880234152492,\n",
       " 0.01745814359697275,\n",
       " 0.004480659724384829,\n",
       " 0.0004406453874165183,\n",
       " 0.0006071615864887373,\n",
       " 0.03385355781485009,\n",
       " 0.002233739051208172,\n",
       " 0.0006504700389126427,\n",
       " 4.161914570992897e-06,\n",
       " 0.0002148122866470155,\n",
       " 0.00022994825627647297,\n",
       " 0.0017058711434723155,\n",
       " 0.008341429586772706,\n",
       " 0.01567517196609258,\n",
       " 0.008421214253652852,\n",
       " 2.2863417877826568e-05,\n",
       " 0.04789332412200306,\n",
       " 0.0015093644649944197,\n",
       " 0.1540952816496057,\n",
       " 0.004544993465885902,\n",
       " 0.0005254929124450466,\n",
       " 0.0002065903983285081,\n",
       " 0.007590545971428308,\n",
       " 0.008590663960356354,\n",
       " 0.0004000199661999787,\n",
       " 0.013626711081854228,\n",
       " 0.03234080511965924,\n",
       " 0.009055448451428524,\n",
       " 9.209570202768709e-05,\n",
       " 0.0008667251377557722,\n",
       " 0.0016856176028470116,\n",
       " 7.473733041263132e-05,\n",
       " 0.0031852110345233333,\n",
       " 0.0198736831562103,\n",
       " 0.0002156639672556076,\n",
       " 0.03204991739545469,\n",
       " 0.013618272119734902,\n",
       " 0.008779126323566823,\n",
       " 0.003505856444513642,\n",
       " 0.0009677927552525305,\n",
       " 0.0694782126484115,\n",
       " 0.001800806023233487,\n",
       " 0.062315296736414956,\n",
       " 0.0001164975035103559,\n",
       " 0.003936950804494763,\n",
       " 0.002567709742360782,\n",
       " 0.00021375789096655088,\n",
       " 0.0011938260998600283,\n",
       " 0.052856835273491144,\n",
       " 0.00019068673460033995,\n",
       " 0.025975376425538314,\n",
       " 0.0010748482693514472,\n",
       " 0.015457330879760572,\n",
       " 7.952292107558286e-05,\n",
       " 0.001162749049369903,\n",
       " 0.04000095476926959,\n",
       " 0.0008280521267496673,\n",
       " 0.000436463538185977,\n",
       " 0.0006662497037835442,\n",
       " 0.0004100237003968213]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
