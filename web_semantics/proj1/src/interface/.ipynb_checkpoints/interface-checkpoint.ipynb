{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yi's Parser Code\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as req\n",
    "\n",
    "def gpx_parser(file):\n",
    "    root = ET.parse(file).getroot()\n",
    "    \n",
    "    # root[0].tag is 'metadata', root[0][0].tag is 'name'\n",
    "    trk_name = root[0][0].text\n",
    "    \n",
    "    # root[-1].tag is 'trk', root[-1][0].tag is 'name'\n",
    "    assert trk_name == root[-1][0].text\n",
    "    \n",
    "    #here we need to account for names needing to be one coherent unit under TTL rules\n",
    "    trk_name = trk_name.replace(\" \", \"_\")\n",
    "        \n",
    "    trk_wpts = {}\n",
    "    for x in root[1:-1]:\n",
    "        # x.tag is 'wpt'\n",
    "        wpt_loc = (x.attrib['lat'], x.attrib['lon']) # :hasloc\n",
    "        # x[0].tag is 'ele'\n",
    "        wpt_ele = x[0].text # :hasele       \n",
    "        # x[1].tag is 'time'\n",
    "        #wpt_time = x[1].text # :hastime\n",
    "        wpt_time = x[1].text.replace(\":\", \"_\") #time fix\n",
    "        wpt_time = wpt_time.replace(\"+\", \"p\")\n",
    "        # x[2].tag is 'name'\n",
    "        #wpt_name = x[2].text # :hasname\n",
    "        wpt_name = x[2].text.replace(\" \", \"_\")\n",
    "        \n",
    "        wpt = 'wpt' + wpt_ele\n",
    "        trk_wpts[wpt] = {'loc': wpt_loc, 'ele': wpt_ele, 'time': wpt_time, 'name': wpt_name}\n",
    "        \n",
    "        \n",
    "    trk_trkpts = {}\n",
    "    # root[-1].tag is 'trk', root[-1][1].tag is 'trkseg'\n",
    "    for x in root[-1][1][:]:\n",
    "        # x.tag is 'trkpt'\n",
    "        trkpt_loc = (x.attrib['lat'], x.attrib['lon']) # :hasloc\n",
    "        # x[0].tag is 'ele'\n",
    "        trkpt_ele = x[0].text # :hasele       \n",
    "        # x[1].tag is 'time'\n",
    "        #trkpt_time = x[1].text # :hastime\n",
    "        trkpt_time = x[1].text.replace(\":\", \"_\") #time fix\n",
    "        trkpt_time = trkpt_time.replace(\"+\",\"p\")\n",
    "        \n",
    "        trkpt = 'trkpt' + trkpt_ele\n",
    "        trk_trkpts[trkpt] = {'loc': trkpt_loc, 'ele': trkpt_ele, 'time': trkpt_time}\n",
    "        \n",
    "    return trk_name, trk_wpts, trk_trkpts\n",
    "\n",
    "def link2osm(gpx_file):    \n",
    "    trk_name, trk_wpts, trk_trkpts = gpx_parser(gpx_file)\n",
    "    \n",
    "    wpt_lats = [float(trk_wpts[wpt]['loc'][0]) for wpt in trk_wpts]\n",
    "    wpt_minlat, wpt_maxlat = min(wpt_lats), max(wpt_lats)\n",
    "    wpt_lons = [float(trk_wpts[wpt]['loc'][1]) for wpt in trk_wpts]\n",
    "    wpt_minlon, wpt_maxlon = min(wpt_lons), max(wpt_lons)\n",
    "    \n",
    "    trkpt_lats = [float(trk_trkpts[trkpt]['loc'][0]) for trkpt in trk_trkpts]\n",
    "    trkpt_minlat, trkpt_maxlat = min(trkpt_lats), max(trkpt_lats)\n",
    "    trkpt_lons = [float(trk_trkpts[trkpt]['loc'][1]) for trkpt in trk_trkpts]\n",
    "    trkpt_minlon, trkpt_maxlon = min(trkpt_lons), max(trkpt_lons)\n",
    "    \n",
    "    #print('wpt min: ', wpt_minlat, wpt_minlon)\n",
    "    #print('wpt max: ', wpt_maxlat, wpt_maxlon)\n",
    "    \n",
    "    #print('trkpt min: ', trkpt_minlat, trkpt_minlon)\n",
    "    #print('trkpt max: ', trkpt_maxlat, trkpt_maxlon)\n",
    "    \n",
    "    # the naive surroundings\n",
    "    minlat = trkpt_minlat - 0.005\n",
    "    minlon = trkpt_minlon - 0.005\n",
    "    maxlat = trkpt_maxlat + 0.005\n",
    "    maxlon = trkpt_maxlon + 0.005\n",
    "    \n",
    "    osm_bounds = (minlat, minlon, maxlat, maxlon)\n",
    "    print('osm bounds: ', osm_bounds)\n",
    "    \n",
    "    bound_lats = [minlat, maxlat, maxlat, minlat, minlat]\n",
    "    bound_lons = [minlon, minlon, maxlon, maxlon, minlon]\n",
    "    \n",
    "    data = ((wpt_lats, wpt_lons), (trkpt_lats, trkpt_lons), (bound_lats, bound_lons))\n",
    "    colors = ('red', 'blue', 'black')\n",
    "    groups = ('wpt', 'trkpt', 'bounds')\n",
    "    \n",
    "    \n",
    "    for data, color, group in zip(data, colors, groups):\n",
    "        x, y = data\n",
    "    \n",
    "        plt.plot(x, y, '-ok', c  = color, label = group)\n",
    "        plt.title('gpx track: %s'%(trk_name))\n",
    "        plt.xlabel('lat')\n",
    "        plt.ylabel('lon')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "   \n",
    "    #plt.show()\n",
    "    \n",
    "    bbox = '%f,%f,%f,%f'%(minlon, minlat, maxlon, maxlat)\n",
    "    osm_file = '%s.osm'%(trk_name)\n",
    "    \n",
    "    req.urlretrieve('https://api.openstreetmap.org/api/0.6/map?bbox=%s'%(bbox), osm_file)\n",
    "  \n",
    "    print('%s downloaded'%(osm_file))\n",
    "    \n",
    "    return osm_file\n",
    "\n",
    "def osm_parser(file):\n",
    "    root = ET.parse(file).getroot()\n",
    "    \n",
    "    # root[0].tag is 'bounds'\n",
    "    assert root[0].tag == 'bounds'\n",
    "    osm_bounds = (root[0].attrib['minlat'], root[0].attrib['minlon'], root[0].attrib['maxlat'], root[0].attrib['maxlon'])\n",
    "    \n",
    "    osm_nds = {}\n",
    "    for x in root.findall('node'):\n",
    "        # x.tag is 'node'\n",
    "        nd_id = x.attrib['id'] # hasid\n",
    "        nd = 'nd' + nd_id\n",
    "        \n",
    "        nd_ts = x.attrib['timestamp'].replace(\":\", \"_\") # hasts\n",
    "        nd_loc = (x.attrib['lat'], x.attrib['lon']) # hasloc\n",
    "        # more objects can be added...\n",
    "        nd_name = 'none' # hasname\n",
    "        nd_isinterested = 'no' # isinterested\n",
    "        \n",
    "        nd_ways = [] # ontheway\n",
    "        nd_rlts = [] # intherlt\n",
    "        \n",
    "        for tag in x.findall('tag'):\n",
    "            tag_k, tag_v = tag.attrib['k'], tag.attrib['v']\n",
    "            \n",
    "            if tag_k == 'name':\n",
    "                nd_name = tag_v\n",
    "                \n",
    "            # definition of 'isinterested' is to be discussed...\n",
    "            #isinterestedtags = ['amenity', 'tourism', 'leisure']\n",
    "            #if tag_k in isinterestedtags:\n",
    "            if (tag_k == 'amenity' or tag_k == 'tourism' or tag_k == 'leisure'):\n",
    "                nd_isinterested = 'yes'\n",
    "                \n",
    "        osm_nds[nd] = {'id': nd_id, 'ts': nd_ts, 'loc': nd_loc, 'name': nd_name, 'isinterested': nd_isinterested, 'ways': nd_ways, 'rlts': nd_rlts}\n",
    "    \n",
    "    osm_ways = {} \n",
    "    for x in root.findall('way'):\n",
    "        # x.tag is 'way'\n",
    "        way_id = x.attrib['id'] # hasid\n",
    "        way = 'way' + way_id\n",
    "        \n",
    "        way_nds = [] # hasnd\n",
    "        # more objects can be added...\n",
    "        way_name = 'none' # hasname\n",
    "        way_isinterested = 'no' # isinterested\n",
    "        \n",
    "        way_rlts = [] # intherlt\n",
    "        \n",
    "        for nd in x.findall('nd'):\n",
    "            nd_ref = nd.attrib['ref']\n",
    "            nd = 'nd' + nd_ref\n",
    "            way_nds.append(nd)\n",
    "            \n",
    "            osm_nds[nd]['ways'].append(way)\n",
    "        \n",
    "        for tag in x.findall('tag'):\n",
    "            tag_k, tag_v = tag.attrib['k'], tag.attrib['v']\n",
    "            \n",
    "            if tag_k == 'name':\n",
    "                nd_name = tag_v\n",
    "            \n",
    "            # definition of 'isinterested' is to be discussed...\n",
    "            if (tag_k == 'amenity' or tag_k == 'tourism' or tag_k == 'leisure'):\n",
    "                way_isinterested = 'yes'\n",
    "\n",
    "        osm_ways[way] = {'id': way_id, 'nds': way_nds, 'name': way_name, 'isinterested': way_isinterested, 'rlts': way_rlts}       \n",
    "    \n",
    "    # if the node is on the way that is interested,\n",
    "    # then the node is interested\n",
    "    for nd in osm_nds:\n",
    "        for way in osm_nds[nd]['ways']:\n",
    "            if osm_ways[way]['isinterested'] == 'yes':\n",
    "                osm_nds[nd]['isinterested'] = 'yes'\n",
    "    \n",
    "    osm_rlts = {}\n",
    "    for x in root.findall('relation'):\n",
    "        # x.tag is 'relation'\n",
    "        rlt_id = x.attrib['id'] # hasid\n",
    "        rlt = 'rlt' + rlt_id\n",
    "        rlt_ways = [] # hasway\n",
    "        rlt_nds = [] # hasnd\n",
    "        rlt_rlts = [] # intherlt\n",
    "        # more objects can be added...\n",
    "        rlt_name = ''\n",
    "        \n",
    "        for member in x.findall('member'):\n",
    "            mtype = member.attrib['type']\n",
    "            \n",
    "            if mtype == 'way':\n",
    "                way_ref = member.attrib['ref']\n",
    "                way = 'way' + way_ref\n",
    "                rlt_ways.append(way)\n",
    "                # the key, way, may be beyond the area\n",
    "                if way in osm_ways:\n",
    "                    osm_ways[way]['rlts'].append(rlt)\n",
    "                \n",
    "            if mtype == 'node':\n",
    "                nd_ref = member.attrib['ref']\n",
    "                nd = 'nd' + nd_ref\n",
    "                rlt_nds.append(nd)\n",
    "                # the key, nd, may be beyond the area\n",
    "                if nd in osm_nds:\n",
    "                    osm_nds[nd]['rlts'].append(rlt)\n",
    "                \n",
    "            if mtype == 'relation':\n",
    "                rlt_ref = member.attrib['ref']\n",
    "                rlt = 'rlt' + rlt_ref\n",
    "                rlt_rlts.append(rlt)\n",
    "                \n",
    "        for tag in x.findall('tag'):\n",
    "            tag_k, tag_v = tag.attrib['k'], tag.attrib['v']\n",
    "            \n",
    "            if tag_k == 'name':\n",
    "                rlt_name = tag_v\n",
    "                \n",
    "        osm_rlts[rlt] = {'id': rlt_id, 'ways': rlt_ways, 'nds': rlt_nds, 'rlts': rlt_rlts, 'name': rlt_name}\n",
    "        \n",
    "    return osm_bounds, osm_nds, osm_ways, osm_rlts\n",
    "\n",
    "def analyzer(gpx_file, nway = 9):\n",
    "    \n",
    "    osm_file = link2osm(gpx_file)    \n",
    "    osm_bounds, osm_nds, osm_ways = osm_parser(osm_file)[:-1]\n",
    "\n",
    "    print('osm bounds:', osm_bounds)\n",
    "     \n",
    "    nd_lats = [float(osm_nds[nd]['loc'][0]) for nd in osm_nds]\n",
    "    nd_lons = [float(osm_nds[nd]['loc'][1]) for nd in osm_nds]\n",
    "    \n",
    "    data = [(nd_lats, nd_lons)]\n",
    "    colors = ['green']\n",
    "    groups = ['nd']\n",
    "    \n",
    "    print('there are %d ways.'%len(osm_ways))\n",
    "    \n",
    "    way_lats, way_lons = {}, {}\n",
    "    for way in osm_ways:\n",
    "        way_nds = osm_ways[way]['nds']\n",
    "        way_lats[way] = [float(osm_nds[nd]['loc'][0]) for nd in way_nds]\n",
    "        way_lons[way] = [float(osm_nds[nd]['loc'][1]) for nd in way_nds]\n",
    "        data.append((way_lats[way], way_lons[way]))\n",
    "        colors.append('red')\n",
    "        groups.append(way)\n",
    "    \n",
    "    way_counter = 0\n",
    "    for data, color, group in zip(data, colors, groups):\n",
    "        if way_counter > nway:\n",
    "            break\n",
    "        x, y = data\n",
    "    \n",
    "        plt.scatter(x, y, c  = color, label = group)\n",
    "        plt.title(osm_file)\n",
    "        plt.xlabel('lat')\n",
    "        plt.ylabel('lon')\n",
    "        plt.grid(True)\n",
    "        if group == 'nd':\n",
    "            plt.legend()\n",
    "        #plt.show()\n",
    "        \n",
    "        way_counter += 1\n",
    "   \n",
    "    plt.show()   \n",
    "\n",
    "def around(loc, osm_nds, radius = 0.005):\n",
    "    \n",
    "    lat, lon = float(loc[0]), float(loc[1])\n",
    "    # naive surrounding, adjusted by radius\n",
    "    minlat, maxlat = (lat - radius), (lat + radius)\n",
    "    minlon, maxlon = (lon - radius), (lon + radius)\n",
    "    \n",
    "    surround = []\n",
    "    for nd in osm_nds:\n",
    "        nd_lat, nd_lon = float(osm_nds[nd]['loc'][0]), float(osm_nds[nd]['loc'][1])\n",
    "        if (nd_lat >= minlat and nd_lat <= maxlat) and (nd_lon >= minlon and nd_lon <= maxlon):\n",
    "            # we only care about the surrounded nodes that is interested\n",
    "            if osm_nds[nd]['isinterested'] == 'yes':\n",
    "                surround.append(nd)\n",
    "    \n",
    "    return surround\n",
    "\n",
    "def gen_rdf(gpx_file):\n",
    "    \n",
    "    trk_name, trk_wpts, trk_trkpts = gpx_parser(gpx_file)  \n",
    "    osm_file = link2osm(gpx_file)\n",
    "    osm_bounds, osm_nds, osm_ways, osm_rlts = osm_parser(osm_file)\n",
    "    \n",
    "    trk_surround = [] # hassurround\n",
    "    trkpt_surround = [] # hassurround\n",
    "    for trkpt in trk_trkpts:\n",
    "        trkpt_loc = trk_trkpts[trkpt]['loc']\n",
    "     \n",
    "        trkpt_surround = around(trkpt_loc, osm_nds)\n",
    "        trk_trkpts[trkpt]['surround'] = trkpt_surround\n",
    "        \n",
    "        trk_surround += trkpt_surround\n",
    "        \n",
    "    trk_surround = list(set(trk_surround))\n",
    "    \n",
    "    trk_surround_ways = []\n",
    "    for nd in trk_surround:\n",
    "        for way in osm_nds[nd]['ways']:\n",
    "            trk_surround_ways.append(way)\n",
    "            \n",
    "    trk_surround_ways = list(set(trk_surround_ways))\n",
    "    \n",
    "    with open('%s.ttl'%(trk_name), 'w') as f:\n",
    "        f.write('@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\\n')\n",
    "        f.write('@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\\n')\n",
    "        f.write('@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\\n')\n",
    "        f.write('\\n')\n",
    "        f.write('@prefix : <http://www.topografix.com/GPX/1/1>. \\n')\n",
    "        f.write('\\n')\n",
    "        \n",
    "        f.write(':%s a :GPXtrack .\\n'%(trk_name))\n",
    "        f.write('\\n')\n",
    "        \n",
    "        ltrk_wpts = ':%s :haswpt '%(trk_name)\n",
    "        for wpt in trk_wpts:\n",
    "            ltrk_wpts += ':%s, '%(wpt)\n",
    "        ltrk_wpts = ltrk_wpts[:-2] + ' .\\n'\n",
    "        f.write(ltrk_wpts)\n",
    "        f.write('\\n')\n",
    "        \n",
    "        ltrk_trkpts = ':%s :hastrkpt '%(trk_name)\n",
    "        for trkpt in trk_trkpts:\n",
    "            ltrk_trkpts += ':%s, '%(trkpt)\n",
    "        ltrk_trkpts = ltrk_trkpts[:-2] + ' .\\n'\n",
    "        f.write(ltrk_trkpts)\n",
    "        f.write('\\n')\n",
    "        \n",
    "        ltrk_surround = ':%s :hassurround '%(trk_name)\n",
    "        for nd in trk_surround:\n",
    "            ltrk_surround += ':%s, '%(nd)\n",
    "        if len(trk_surround) == 0:\n",
    "            ltrk_surround = ltrk_surround[:] + \":none \"+' .\\n'\n",
    "        else:\n",
    "            ltrk_surround = ltrk_surround[:-2] + ' .\\n'\n",
    "        f.write(ltrk_surround)\n",
    "        f.write('\\n')\n",
    "        \n",
    "        for wpt in trk_wpts:\n",
    "            f.write(':%s :hasloc (:%s :%s) ;\\n'%(wpt, trk_wpts[wpt]['loc'][0], trk_wpts[wpt]['loc'][1])) #fixed format (:lat :lon) instead of :(lat, lon)\n",
    "            f.write(' ' * (len(wpt) + 2) + ':hasele :%s ;\\n'%(trk_wpts[wpt]['ele']))\n",
    "            f.write(' ' * (len(wpt) + 2) + ':hastime :%s ;\\n'%(trk_wpts[wpt]['time']))\n",
    "            f.write(' ' * (len(wpt) + 2) + ':hasname :%s .\\n'%(trk_wpts[wpt]['name'].replace(\" \", \"_\")))\n",
    "            f.write('\\n')\n",
    "        \n",
    "        for trkpt in trk_trkpts:\n",
    "            f.write(':%s :hasloc (:%s :%s) ;\\n'%(trkpt, trk_trkpts[trkpt]['loc'][0], trk_trkpts[trkpt]['loc'][1])) #same format fix\n",
    "            f.write(' ' * (len(trkpt) + 2) + ':hasele :%s ;\\n'%(trk_trkpts[trkpt]['ele']))\n",
    "            f.write(' ' * (len(trkpt) + 2) + ':hastime :%s ;\\n'%(trk_trkpts[trkpt]['time']))\n",
    "            ltrk_trkpts_surround = ' ' * (len(trkpt) + 2) + ':hassurround '\n",
    "            for nd in trk_trkpts[trkpt]['surround']:\n",
    "                ltrk_trkpts_surround += ':%s, '%(nd)\n",
    "            if len(trk_trkpts[trkpt]['surround']) == 0:\n",
    "                ltrk_trkpts_surround = ltrk_trkpts_surround[:] + ':none ' +' .\\n'\n",
    "            else:\n",
    "                ltrk_trkpts_surround = ltrk_trkpts_surround[:-2] + ' .\\n'\n",
    "            f.write(ltrk_trkpts_surround)\n",
    "            f.write('\\n')\n",
    "                 \n",
    "        for nd in trk_surround:\n",
    "            name_fix_ = osm_nds[nd]['name'].replace(\" \",\"_\")\n",
    "            name_fix_ = name_fix_.replace(\"'\",\"\")\n",
    "            f.write(':%s :hasloc (:%s :%s) ;\\n'%(nd, osm_nds[nd]['loc'][0], osm_nds[nd]['loc'][1])) #same format fix\n",
    "            f.write(' ' * (len(nd) + 2) + ':hasid :%s ;\\n'%(osm_nds[nd]['id']))\n",
    "            f.write(' ' * (len(nd) + 2) + ':hasts :%s ;\\n'%(osm_nds[nd]['ts'].replace(\":\",\"_\")))\n",
    "            f.write(' ' * (len(nd) + 2) + ':hasname :%s ;\\n'%(name_fix_))\n",
    "            f.write(' ' * (len(nd) + 2) + ':isinterested :%s ;\\n'%(osm_nds[nd]['isinterested']))\n",
    "            ltrk_surround_way = ' ' * (len(nd) + 2) + ':ontheway '\n",
    "            for way in osm_nds[nd]['ways']:\n",
    "                ltrk_surround_way += ':%s, '%(way)\n",
    "            if len(osm_nds[nd]['ways']) == 0:\n",
    "                ltrk_surround_way = ltrk_surround_way[:]+ \":none \" + ' ;\\n'\n",
    "            else:\n",
    "                ltrk_surround_way = ltrk_surround_way[:-2] + ' ;\\n'\n",
    "            f.write(ltrk_surround_way)\n",
    "            ltrk_surround_rlt = ' ' * (len(nd) + 2) + ':intherlt '\n",
    "            for rlt in osm_nds[nd]['rlts']:\n",
    "                ltrk_surround_rlt += ':%s, '%(rlt)\n",
    "            if len(osm_nds[nd]['rlts']) == 0:\n",
    "                ltrk_surround_rlt = ltrk_surround_rlt[:] + \":none \" +' .\\n'\n",
    "            else:\n",
    "                ltrk_surround_rlt = ltrk_surround_rlt[:-2] + ' .\\n'\n",
    "            f.write(ltrk_surround_rlt)\n",
    "            f.write('\\n')\n",
    "            \n",
    "        for way in trk_surround_ways:\n",
    "            fix_name = osm_ways[way]['name'].replace(\" \", \"_\")\n",
    "            fix_name = fix_name.replace(\"'\",\"\")\n",
    "            f.write(':%s :hasid :%s ;\\n'%(way, osm_ways[way]['id']))\n",
    "            f.write(' ' * (len(way) + 2) + ':hasname :%s ;\\n'%(fix_name))\n",
    "            f.write(' ' * (len(way) + 2) + ':isinterested :%s ;\\n'%(osm_ways[way]['isinterested']))\n",
    "            ltrk_surround_way_nd = ' ' * (len(way) + 2) + ':hasnd '\n",
    "            for nd in osm_ways[way]['nds']:\n",
    "                ltrk_surround_way_nd += ':%s, '%(nd)\n",
    "            ltrk_surround_way_nd = ltrk_surround_way_nd[:-2] + ' ;\\n'\n",
    "            f.write(ltrk_surround_way_nd)\n",
    "            ltrk_surround_way_rlt = ' ' * (len(way) + 2) + ':intherlt '\n",
    "            for rlt in osm_ways[way]['rlts']:\n",
    "                ltrk_surround_way_rlt += ':%s, '%(rlt)\n",
    "            if len(osm_ways[way]['rlts']) ==0:\n",
    "                ltrk_surround_way_rlt = ltrk_surround_way_rlt[:] + ':none ' + ' .\\n'\n",
    "            else:\n",
    "                ltrk_surround_way_rlt = ltrk_surround_way_rlt[:-2] + ' .\\n'\n",
    "            f.write(ltrk_surround_way_rlt)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run gen RDF on all GPX tracks files\n",
    "def download_all_GPX ():\n",
    "    for file in ['4sDDFdd4cjA.gpx', 'btSeByOExEc.gpx', 'kmrcRbHcMpg.gpx', 'PO21QxqG2co.gpx', 'pRAjjKqHwzQ.gpx', 'rx1-4gf5lts.gpx', 'tIRn_qJSB5s.gpx', 'UAQjXL9WRKY.gpx']:\n",
    "        gen_rdf('./GPX_Tracks/{0}'.format(file)) #download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kense's DBpedia queries\n",
    "from SPARQLWrapper import SPARQLWrapper\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def query_DBpedia (query):\n",
    "    '''\n",
    "    obtain the JSON of the query to the DBpedia database.\n",
    "    '''\n",
    "\n",
    "    db = SPARQLWrapper(\"http://dbpedia.org/sparql/\") #query DBpedia via SPARQL\n",
    "    db.setQuery(query)\n",
    "    db.method = \"POST\"\n",
    "    db.setReturnFormat('json')\n",
    "    db.queryType = \"SELECT\"\n",
    "    result = db.query().convert()\n",
    "\n",
    "    return result\n",
    "\n",
    "def inquire_place (name):\n",
    "    \n",
    "    #query DBpedia based on name\n",
    "    query = \"PREFIX dbo: <http://dbpedia.org/ontology/> \\\n",
    "    PREFIX geo:  <http://www.w3.org/2003/01/geo/wgs84_pos#> \\\n",
    "    SELECT DISTINCT ?place ?label ?lat ?lng \\\n",
    "    WHERE { ?place a dbo:Place . \\\n",
    "    ?place rdfs:label ?label  \\\n",
    "    FILTER (?label IN ( '%s'@en )) . \\\n",
    "    ?place geo:lat ?lat . \\\n",
    "    ?place geo:long ?lng .}\" % name\n",
    "\n",
    "    inquiry = query_DBpedia(query)\n",
    "    \n",
    "    #no results\n",
    "    if len(inquiry['results']['bindings']) == 0:\n",
    "        return (None, None, None, None)\n",
    "    \n",
    "    else:\n",
    "        #query results\n",
    "        dbpedia_url = inquiry['results']['bindings'][0]['place']['value']\n",
    "        lat = inquiry['results']['bindings'][0]['lat']['value']\n",
    "        lng = inquiry['results']['bindings'][0]['lng']['value']\n",
    "        name = inquiry['results']['bindings'][0]['label']['value']\n",
    "        comment = 'none' #defaults none \n",
    "        country = 'none'\n",
    "        postalCode = 'none'\n",
    "        max_ele, min_ele, ele = 'none', 'none', 'none'\n",
    "        \n",
    "        #download XML file\n",
    "        xml_file = requests.get(dbpedia_url)\n",
    "        open('./%s.xml'%name, 'wb').write(xml_file.content)\n",
    "        \n",
    "        #get comment, and some relevant info\n",
    "        fp = open(\"./%s.xml\"%name, \"r\")\n",
    "        soup = BeautifulSoup(fp, 'xml')\n",
    "        \n",
    "        #check spans\n",
    "        for item in soup.find_all(\"span\"):\n",
    "            if item.get('property') == 'dbo:abstract': #get comment\n",
    "                if item.get('xml:lang') == \"en\":\n",
    "                    comment = item.get_text()\n",
    "            if item.get('property') == 'dbo:postalCode': #get postalCode\n",
    "                postalCode = item.get_text()\n",
    "            if item.get('property') == \"dbo:maximumElevation\": #max elevation\n",
    "                max_ele = item.get_text()\n",
    "            if item.get('property') == \"dbo:minimumElevation\": #min elevation\n",
    "                min_ele = item.get_text()\n",
    "            if not max_ele == 'none' and not min_ele == 'none': #elevation calc\n",
    "                ele = str((float(max_ele)+float(min_ele))/2)\n",
    "        \n",
    "        #check a's\n",
    "        for item in soup.find_all(\"a\"):\n",
    "            if item.get('rel') == \"dbo:country\": #get country\n",
    "                country = item.get_text()\n",
    "        \n",
    "        #output\n",
    "        print('DBpedia entry found!')\n",
    "        print('Downloaded XML file...')\n",
    "        return (name, lat, lng, dbpedia_url, ele, country, postalCode, comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do for EACH TTL file:\n",
    "#display a graph (using yi's code)\n",
    "#display relevant information from dbpedia (using kense's queries)\n",
    "\n",
    "#download_all_GPX() #downloads all TTL files\n",
    "\n",
    "#load TTL files into GraphDB and establish a query point\n",
    "\n",
    "#query GraphDB for EACH ttl file, take a look at sparqlwrapper for ideas\n",
    "\n",
    "#query all possible dbpedia for EACH ttl file\n",
    "\n",
    "#display information as static pages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
