{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ning\n",
    "#03 November 2019\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the json file into a dictionary\n",
    "jsonfp = open(\"toygrammar.json\", \"r\")\n",
    "json_grammar = json.load(jsonfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 'S',\n",
       " 'NTR': [['S', 'NP', 'VP', 1.0],\n",
       "  ['NP', 'DET', 'N', 0.4],\n",
       "  ['NP', 'DET', 'NPP', 0.6],\n",
       "  ['NPP', 'N', 'PP', 1.0],\n",
       "  ['VP', 'V', 'NP', 0.3],\n",
       "  ['VP', 'V', 'NPPP', 0.7],\n",
       "  ['NPPP', 'NP', 'PP', 1.0],\n",
       "  ['PP', 'P', 'NP', 1.0]],\n",
       " 'TR': [['DET', 'the', 1.0],\n",
       "  ['N', 'girl', 0.3],\n",
       "  ['N', 'man', 0.5],\n",
       "  ['N', 'telescope', 0.2],\n",
       "  ['V', 'sees', 0.6],\n",
       "  ['V', 'watches', 0.4],\n",
       "  ['P', 'with', 1.0]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that we listed the information correctly\n",
    "json_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordering the dictionary in order to comply with section 1 subpoint 6: \n",
    "\"\"\"It might be useful to store the rules as dictionaries of dictionaries, using the left\n",
    "hand side as the first key, the right hand side as the second key, and the probability\n",
    "as the value.\"\"\"\n",
    "grammar = {}\n",
    "unit_reverse = {}\n",
    "\n",
    "for item in json_grammar[\"NTR\"]: #goes through all non-terminating rules\n",
    "    \n",
    "    #define the parts\n",
    "    lhs = \"{0}\".format(item[0])\n",
    "    \n",
    "    if not lhs in grammar: #if we don't already have this lhs hashed\n",
    "        rhs = {} #create new\n",
    "        rhs[\"{0} {1}\".format(item[1], item[2])] = item[3] #define the rhs\n",
    "        grammar[lhs] = rhs #hash it into grammar\n",
    "    else:\n",
    "        grammar[lhs][\"{0} {1}\".format(item[1], item[2])] = item[3] #just hash\n",
    "\n",
    "for item in json_grammar[\"TR\"]: #just copy over the terminating rules?\n",
    "    \n",
    "    #define the parts\n",
    "    lhs = \"{0}\".format(item[0])\n",
    "    \n",
    "    if not lhs in grammar:\n",
    "        rhs = {} #set new\n",
    "        rhs[\"{0}\".format(item[1])] = item[2] #define the rhs\n",
    "        grammar[lhs] = rhs #hashes into the grammar\n",
    "    else:\n",
    "        grammar[lhs][\"{0}\".format(item[1])] = item[2] #hashes into the grammar\n",
    "\n",
    "#Note that we also want the terminating words as keys so that searching backwards is doable\n",
    "for item in json_grammar[\"TR\"]:\n",
    "    word = \"{0}\".format(item[1])\n",
    "    reverse = \"{0}\".format(item[0])\n",
    "    unit_reverse[word] = reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': {'NP VP': 1.0}, 'NP': {'DET N': 0.4, 'DET NPP': 0.6}, 'NPP': {'N PP': 1.0}, 'VP': {'V NP': 0.3, 'V NPPP': 0.7}, 'NPPP': {'NP PP': 1.0}, 'PP': {'P NP': 1.0}, 'DET': {'the': 1.0}, 'N': {'girl': 0.3, 'man': 0.5, 'telescope': 0.2}, 'V': {'sees': 0.6, 'watches': 0.4}, 'P': {'with': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "#confirms that the grammar is stored as desired\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following the pseudo code implementation\n",
    "def cyk_me_up_fam(sentence, grammar, unit_reverse):\n",
    "    \n",
    "    '''\n",
    "    sentence should be an array input of words in order\n",
    "    grammar should be a dictionary set up properly\n",
    "    '''\n",
    "    \n",
    "    n = len(sentence) #input size\n",
    "    grid = [x[:] for x in [[None]*n]*n]\n",
    "    \n",
    "    #prelims -> sets the first row of unit prods\n",
    "    for q in range(0,n):\n",
    "        grid[0][q] = unit_reverse[sentence[q]] #first row contains the marker for unit prod\n",
    "    \n",
    "    #elims -> grey-box checks if lhs can produce f_val s_val \n",
    "\n",
    "    #potential productions, denoted f_val, s_val\n",
    "    for l in range(2, n+1):\n",
    "        for s in range(1, n-l+2):\n",
    "            for p in range(1, l-1+1):\n",
    "\n",
    "                f_val = grid[p-1][s-1] #first run should be p,s = 0,0 and l-p,s+p = 0,1\n",
    "                s_val = grid[l-p-1][s+p-1] #second run p,s = 0,1 and l-p,s+p = 0,2\n",
    "\n",
    "                potpro = \"{0} {1}\".format(f_val, s_val) #potential production\n",
    "\n",
    "                #check lhs' dictionaries to see if there exist a key that corresponds\n",
    "                lhs = list(grammar.keys())\n",
    "                for keys in lhs:\n",
    "                    rhs = list(grammar[keys].keys())\n",
    "                    if potpro in rhs: #match, align the box\n",
    "                        grid[l-1][s-1] = keys\n",
    "                        #do book-keepng here for probabilities\n",
    "                        \n",
    "                        \n",
    "    #return the tree and probability here\n",
    "    ret = []\n",
    "    for col in range(0, n): #for each slot down the grid\n",
    "        for row in range(n-1, -1, -1):\n",
    "            if grid[row][col] != None:\n",
    "                ret.append(\"{0} \".format(grid[row][col]))\n",
    "    \n",
    "    #we can figure out how to properly organize tree in a bit\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DET', 'N', 'V', 'DET', 'N'], ['NP', None, None, 'NP', None], [None, None, 'VP', None, None], [None, None, None, None, None], ['S', None, None, None, None]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['S ', 'NP ', 'DET ', 'N ', 'VP ', 'V ', 'NP ', 'DET ', 'N ']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyk_me_up_fam([\"the\", \"girl\", \"sees\", \"the\", \"telescope\"], grammar, unit_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
